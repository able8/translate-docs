# Container Networking Is Simple!

# å®¹å™¨ç½‘ç»œå¾ˆç®€å•ï¼

October 18, 2020 (Updated: August 4, 2021)

_**Just kidding, it's not... But fear not and read on!**_

_**å¼€ä¸ªç©ç¬‘ï¼Œè¿™ä¸æ˜¯......ä½†ä¸è¦å®³æ€•ï¼Œç»§ç»­é˜…è¯»ï¼**_

_You can find a Russian translation of this article [here](https://habr.com/ru/company/timeweb/blog/558612/)_.

_æ‚¨å¯ä»¥åœ¨ [æ­¤å¤„](https://habr.com/ru/company/timeweb/blog/558612/)_ ä¸­æ‰¾åˆ°æœ¬æ–‡çš„ä¿„è¯­ç¿»è¯‘ã€‚

Working with containers always feels like magic. In a good way for those who understand the internals and in a terrifying - for those who don't. Luckily, we've been looking under the hood of the containerization technology for quite some time already and even managed to uncover that [containers are just isolated and restricted Linux processes](http://iximiuz.com/en/posts/not-every-container-has-an-operating-system-inside/#container-is-just-a-processes), that [images aren't really needed to run containers](http://iximiuz.com/en/posts/you-dont-need-an-image-to-run-a-container/), and on the contrary - [to build an image we need to run some containers](http://iximiuz.com/en/posts/you-need-containers-to-build-an-image/).

ä½¿ç”¨å®¹å™¨æ€»æ˜¯æ„Ÿè§‰åƒé­”æœ¯ä¸€æ ·ã€‚å¯¹äºé‚£äº›äº†è§£å†…éƒ¨ç»“æ„çš„äººæ¥è¯´è¿™æ˜¯ä¸€ç§å¾ˆå¥½çš„æ–¹å¼ï¼Œè€Œå¯¹äºé‚£äº›ä¸äº†è§£å†…éƒ¨ç»“æ„çš„äººæ¥è¯´åˆ™æ˜¯ä¸€ç§å¯æ€•çš„æ–¹å¼ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å·²ç»ç ”ç©¶äº†å®¹å™¨åŒ–æŠ€æœ¯çš„å¹•åå¾ˆé•¿ä¸€æ®µæ—¶é—´ï¼Œç”šè‡³è®¾æ³•å‘ç° å®¹å™¨åªæ˜¯éš”ç¦»å’Œå—é™åˆ¶çš„ Linux è¿›ç¨‹ï¼Œ[è¿è¡Œå®¹å™¨å¹¶ä¸çœŸæ­£éœ€è¦å›¾åƒ](http://iximiuz.com/en/posts/you-dont-need-an-image-to-run-a-container/)ï¼Œç›¸å - [è¦æ„å»ºæ˜ åƒï¼Œæˆ‘ä»¬éœ€è¦è¿è¡Œä¸€äº›å®¹å™¨](http://iximiuz.com/en/posts/you-need-containers-to-build-an-image/)ã€‚

Now comes a time to tackle the container networking problem. Or, more precisely, a single-host container networking problem. In this article, we are going to answer the following questions:

ç°åœ¨æ˜¯è§£å†³å®¹å™¨ç½‘ç»œé—®é¢˜çš„æ—¶å€™äº†ã€‚æˆ–è€…ï¼Œæ›´å‡†ç¡®åœ°è¯´ï¼Œæ˜¯å•ä¸»æœºå®¹å™¨ç½‘ç»œé—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

- How to virtualize network resources to make containers think each of them has a dedicated network stack?
- How to turn containers into friendly neighbors, prevent them from interfering, and teach to communicate well?
- How to reach the outside world (e.g. the Internet) from inside the container?
- How to reach containers running on a machine from the outside world ( _aka_ port publishing)?

- å¦‚ä½•è™šæ‹ŸåŒ–ç½‘ç»œèµ„æºï¼Œè®©å®¹å™¨è®¤ä¸ºå®ƒä»¬æ¯ä¸ªéƒ½æœ‰ä¸€ä¸ªä¸“ç”¨çš„ç½‘ç»œå †æ ˆï¼Ÿ
- å¦‚ä½•å°†é›†è£…ç®±å˜æˆå‹å¥½çš„é‚»å±…ï¼Œé˜²æ­¢ä»–ä»¬å¹²æ‰°ï¼Œå¹¶æ•™ä»–ä»¬è‰¯å¥½çš„æ²Ÿé€šï¼Ÿ
- å¦‚ä½•ä»å®¹å™¨å†…éƒ¨è®¿é—®å¤–éƒ¨ä¸–ç•Œï¼ˆä¾‹å¦‚äº’è”ç½‘ï¼‰ï¼Ÿ
- å¦‚ä½•ä»å¤–éƒ¨ä¸–ç•Œï¼ˆ_aka_ ç«¯å£å‘å¸ƒï¼‰è®¿é—®æœºå™¨ä¸Šè¿è¡Œçš„å®¹å™¨ï¼Ÿ

While answering these questions, we'll setup a container networking from scratch using standard Linux tools. As a result, it'll become apparent that the single-host container networking is nothing more than a simple combination of the well-known Linux facilities:

åœ¨å›ç­”è¿™äº›é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ ‡å‡† Linux å·¥å…·ä»å¤´å¼€å§‹è®¾ç½®å®¹å™¨ç½‘ç»œã€‚å› æ­¤ï¼Œå¾ˆæ˜æ˜¾ï¼Œå•ä¸»æœºå®¹å™¨ç½‘ç»œåªä¸è¿‡æ˜¯ä¼—æ‰€å‘¨çŸ¥çš„ Linux å·¥å…·çš„ç®€å•ç»„åˆï¼š

- network namespaces;
- virtual Ethernet devices (veth);
- virtual network switches (bridge);
- IP routing and network address translation (NAT).

- ç½‘ç»œå‘½åç©ºé—´ï¼›
- è™šæ‹Ÿä»¥å¤ªç½‘è®¾å¤‡ï¼ˆvethï¼‰ï¼›
- è™šæ‹Ÿç½‘ç»œäº¤æ¢æœºï¼ˆç½‘æ¡¥ï¼‰ï¼›
- IP è·¯ç”±å’Œç½‘ç»œåœ°å€è½¬æ¢ (NAT)ã€‚

And for better or worse, no code is required to make the networking magic happen...

ä¸ç®¡æ˜¯å¥½æ˜¯åï¼Œä¸éœ€è¦ä»»ä½•ä»£ç æ¥å®ç°ç½‘ç»œé­”æ³•â€¦â€¦

## Prerequisites

## å…ˆå†³æ¡ä»¶

Any decent Linux distribution would probably suffice. All the examples in the article have been made on a fresh _vagrant_ CentOS 8 virtual machine:

ä»»ä½•ä½“é¢çš„ Linux å‘è¡Œç‰ˆå¯èƒ½å°±è¶³å¤Ÿäº†ã€‚æ–‡ç« ä¸­çš„æ‰€æœ‰ç¤ºä¾‹éƒ½æ˜¯åœ¨å…¨æ–°çš„ _vagrant_ CentOS 8 è™šæ‹Ÿæœºä¸Šåˆ¶ä½œçš„ï¼š

```bash
$ vagrant init centos/8
$ vagrant up
$ vagrant ssh

[vagrant@localhost ~]$ uname -a
Linux localhost.localdomain 4.18.0-147.3.1.el8_1.x86_64

```

For the sake of simplicity of the examples, in this article, we are not going to rely on any fully-fledged containerization solution (e.g. _docker_ or _podman_). Instead, we'll focus on the basic concepts and use the bare minimum tooling to achieve our learning goals.

ä¸ºäº†ç¤ºä¾‹çš„ç®€å•èµ·è§ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šä¾èµ–ä»»ä½•æˆç†Ÿçš„å®¹å™¨åŒ–è§£å†³æ–¹æ¡ˆï¼ˆä¾‹å¦‚ _docker_ æˆ– _podman_ï¼‰ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºåŸºæœ¬æ¦‚å¿µå¹¶ä½¿ç”¨æœ€å°‘çš„å·¥å…·æ¥å®ç°æˆ‘ä»¬çš„å­¦ä¹ ç›®æ ‡ã€‚

## Isolating containers with network namespaces

## ä½¿ç”¨ç½‘ç»œå‘½åç©ºé—´éš”ç¦»å®¹å™¨

What constitutes a Linux network stack? Well, obviously, the set of network devices. What else? Probably, the set of routing rules. And not to forget, the set of netfilter hooks, including defined by iptables rules.

ä»€ä¹ˆæ„æˆäº† Linux ç½‘ç»œå †æ ˆï¼Ÿå—¯ï¼Œå¾ˆæ˜æ˜¾ï¼Œç½‘ç»œè®¾å¤‡çš„é›†åˆã€‚è¿˜æœ‰ä»€ä¹ˆï¼Ÿå¯èƒ½æ˜¯è·¯ç”±è§„åˆ™é›†ã€‚ä¸è¦å¿˜è®°ï¼Œä¸€ç»„ netfilter é’©å­ï¼ŒåŒ…æ‹¬ç”± iptables è§„åˆ™å®šä¹‰çš„ã€‚

We can quickly forge a non-comprehensive `inspect-net-stack.sh` script:

æˆ‘ä»¬å¯ä»¥å¿«é€Ÿä¼ªé€ ä¸€ä¸ªä¸å…¨é¢çš„ `inspect-net-stack.sh` è„šæœ¬ï¼š

```bash
#!/usr/bin/env bash

echo "> Network devices"
ip link

echo -e "\n> Route table"
ip route

echo -e "\n> Iptables rules"
iptables --list-rules

```

Before running it, let's taint the iptables rules a bit to make them recognizable:

åœ¨è¿è¡Œå®ƒä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç¨å¾®ä¿®æ”¹ä¸€ä¸‹ iptables è§„åˆ™ä»¥ä½¿å…¶æ˜“äºè¯†åˆ«ï¼š

```bash
$ sudo iptables -N ROOT_NS

```

After that, execution of the inspect script on my machine produces the following output:

ä¹‹åï¼Œåœ¨æˆ‘çš„æœºå™¨ä¸Šæ‰§è¡Œæ£€æŸ¥è„šæœ¬ä¼šäº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š

```bash
$ sudo ./inspect-net-stack.sh
> Network devices
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff

> Route table
default via 10.0.2.2 dev eth0 proto dhcp metric 100
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100

> Iptables rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT
-N ROOT_NS

```

We are interested in that output because we want to make sure that each of the containers we are going to create soon will get a separate network stack. 

æˆ‘ä»¬å¯¹è¯¥è¾“å‡ºæ„Ÿå…´è¶£ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³ç¡®ä¿æˆ‘ä»¬å³å°†åˆ›å»ºçš„æ¯ä¸ªå®¹å™¨éƒ½å°†è·å¾—ä¸€ä¸ªå•ç‹¬çš„ç½‘ç»œå †æ ˆã€‚

Well, you might have heard already, that one of the Linux namespaces used for containers isolation is called _network namespace_. From [`man ip-netns`](https://man7.org/linux/man-pages/man8/ip-netns.8.html), _"network namespace is logically another copy of the network stack, with its own routes, firewall rules, and network devices."_ For the sake of simplicity, this is the only namespace we're going to use in this article. Instead of creating fully-isolated containers, we'd rather restrict the scope to only the network stack.

å¥½å§ï¼Œæ‚¨å¯èƒ½å·²ç»å¬è¯´è¿‡ï¼Œç”¨äºå®¹å™¨éš”ç¦»çš„ Linux å‘½åç©ºé—´ä¹‹ä¸€ç§°ä¸º _network namespace_ã€‚æ¥è‡ª [`man ip-netns`](https://man7.org/linux/man-pages/man8/ip-netns.8.html)ï¼Œ_"network å‘½åç©ºé—´åœ¨é€»è¾‘ä¸Šæ˜¯ç½‘ç»œå †æ ˆçš„å¦ä¸€ä¸ªå‰¯æœ¬ï¼Œå…¶è‡ªå·±çš„è·¯ç”±ã€é˜²ç«å¢™è§„åˆ™å’Œç½‘ç»œè®¾å¤‡ã€‚â€_ ä¸ºç®€å•èµ·è§ï¼Œè¿™æ˜¯æˆ‘ä»¬å°†åœ¨æœ¬æ–‡ä¸­ä½¿ç”¨çš„å”¯ä¸€å‘½åç©ºé—´ã€‚ä¸å…¶åˆ›å»ºå®Œå…¨éš”ç¦»çš„å®¹å™¨ï¼Œä¸å¦‚å°†èŒƒå›´é™åˆ¶åœ¨ç½‘ç»œå †æ ˆä¸Šã€‚

One of the ways to create a network namespace is the `ip` tool - part of the de facto standard [iproute2](https://en.wikipedia.org/wiki/Iproute2) collection:

åˆ›å»ºç½‘ç»œå‘½åç©ºé—´çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ `ip` å·¥å…· - äº‹å®æ ‡å‡† [iproute2](https://en.wikipedia.org/wiki/Iproute2) é›†åˆçš„ä¸€éƒ¨åˆ†ï¼š

```bash
$ sudo ip netns add netns0
$ ip netns
netns0
```

How to start using the just created namespace? There is a lovely Linux command called `nsenter`. It enters one or more of the specified namespaces and then executes the given program:

å¦‚ä½•å¼€å§‹ä½¿ç”¨åˆšåˆšåˆ›å»ºçš„å‘½åç©ºé—´ï¼Ÿæœ‰ä¸€ä¸ªå¯çˆ±çš„ Linux å‘½ä»¤å«åš `nsenter`ã€‚å®ƒè¿›å…¥ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‡å®šçš„å‘½åç©ºé—´ï¼Œç„¶åæ‰§è¡Œç»™å®šçš„ç¨‹åºï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0 bash
# The newly created bash process lives in netns0

$ sudo ./inspect-net-stack.sh
> Network devices
1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00

> Route table

> Iptables rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT

```

From the output above it's clear that the _bash_ process running inside `netns0` namespace sees a totally different network stack. There is no routing rules at all, no custom iptables chain, and only one loopback network device. So far, so good...

ä»ä¸Šé¢çš„è¾“å‡ºå¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œåœ¨ `netns0` å‘½åç©ºé—´å†…è¿è¡Œçš„ _bash_ è¿›ç¨‹çœ‹åˆ°äº†ä¸€ä¸ªå®Œå…¨ä¸åŒçš„ç½‘ç»œå †æ ˆã€‚å®Œå…¨æ²¡æœ‰è·¯ç”±è§„åˆ™ï¼Œæ²¡æœ‰è‡ªå®šä¹‰iptablesé“¾ï¼Œåªæœ‰ä¸€ä¸ªloopbackç½‘ç»œè®¾å¤‡ã€‚åˆ°ç°åœ¨ä¸ºæ­¢è¿˜æŒºå¥½...

![Linux network namespace visualized](http://iximiuz.com/container-networking-is-simple/network-namespace-4000-opt.png)

_Network namespace visualized._

_ç½‘ç»œå‘½åç©ºé—´å¯è§†åŒ–ã€‚_

## Connecting containers to host with virtual Ethernet devices (veth)

## ä½¿ç”¨è™šæ‹Ÿä»¥å¤ªç½‘è®¾å¤‡ï¼ˆvethï¼‰å°†å®¹å™¨è¿æ¥åˆ°ä¸»æœº

A dedicated network stack would be not so useful if we could not communicate with it. Luckily, Linux provides a suitable facility for that - a virtual Ethernet device! From [`man veth`](https://man7.org/linux/man-pages/man4/veth.4.html), _"veth devices are virtual Ethernet devices. They can act as tunnels between network namespaces to create a bridge to a physical network device in another namespace, but can also be used as standalone network devices."_

å¦‚æœæˆ‘ä»¬ä¸èƒ½ä¸ä¹‹é€šä¿¡ï¼Œä¸“ç”¨çš„ç½‘ç»œå †æ ˆå°†ä¸ä¼šé‚£ä¹ˆæœ‰ç”¨ã€‚å¹¸è¿çš„æ˜¯ï¼ŒLinux æä¾›äº†ä¸€ä¸ªåˆé€‚çš„å·¥å…·â€”â€”ä¸€ä¸ªè™šæ‹Ÿä»¥å¤ªç½‘è®¾å¤‡ï¼æ¥è‡ª [`man veth`](https://man7.org/linux/man-pages/man4/veth.4.html)ï¼Œ_"veth è®¾å¤‡æ˜¯è™šæ‹Ÿä»¥å¤ªç½‘è®¾å¤‡ã€‚å®ƒä»¬å¯ä»¥å……å½“ç½‘ç»œå‘½åç©ºé—´ä¹‹é—´çš„éš§é“æ¥åˆ›å»ºè¿æ¥åˆ°å¦ä¸€ä¸ªå‘½åç©ºé—´ä¸­çš„ç‰©ç†ç½‘ç»œè®¾å¤‡çš„æ¡¥æ¥å™¨ï¼Œä½†ä¹Ÿå¯ä»¥ç”¨ä½œç‹¬ç«‹çš„ç½‘ç»œè®¾å¤‡ã€‚â€_

Virtual Ethernet devices always go in pairs. No worries, it'll be clear when we take a look at the creation command:

è™šæ‹Ÿä»¥å¤ªç½‘è®¾å¤‡æ€»æ˜¯æˆå¯¹ä½¿ç”¨ã€‚ä¸ç”¨æ‹…å¿ƒï¼Œå½“æˆ‘ä»¬çœ‹ä¸€ä¸‹åˆ›å»ºå‘½ä»¤æ—¶å°±ä¼šå¾ˆæ¸…æ¥šï¼š

```bash
$ sudo ip link add veth0 type veth peer name ceth0
```

With this single command, we just created a pair of _interconnected_ virtual Ethernet devices. The names `veth0` and `ceth0` have been chosen arbitrarily:

ä½¿ç”¨è¿™ä¸ªå•ä¸€å‘½ä»¤ï¼Œæˆ‘ä»¬åˆšåˆšåˆ›å»ºäº†ä¸€å¯¹ _interconnected_ è™šæ‹Ÿä»¥å¤ªç½‘è®¾å¤‡ã€‚åç§° `veth0` å’Œ `ceth0` æ˜¯ä»»æ„é€‰æ‹©çš„ï¼š

```bash
$ ip link
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
5: ceth0@veth0: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 66:2d:24:e3:49:3f brd ff:ff:ff:ff:ff:ff
6: veth0@ceth0: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 96:e8:de:1d:22:e0 brd ff:ff:ff:ff:ff:ff
```

Both `veth0` and `ceth0` after creation resides on the host's network stack (also called root network namespace). To connect the root namespace with the `netns0` namespace, we need to keep one of the devices in the root namespace and move another one into the `netns0`:

åˆ›å»ºåçš„ `veth0` å’Œ `ceth0` éƒ½é©»ç•™åœ¨ä¸»æœºçš„ç½‘ç»œå †æ ˆï¼ˆä¹Ÿç§°ä¸ºæ ¹ç½‘ç»œå‘½åç©ºé—´ï¼‰ä¸Šã€‚è¦å°†æ ¹å‘½åç©ºé—´ä¸ `netns0` å‘½åç©ºé—´è¿æ¥èµ·æ¥ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶ä¸­ä¸€å°è®¾å¤‡ä¿ç•™åœ¨æ ¹å‘½åç©ºé—´ä¸­ï¼Œå¹¶å°†å¦ä¸€å°è®¾å¤‡ç§»åŠ¨åˆ° `netns0` ä¸­ï¼š

```bash
$ sudo ip link set ceth0 netns netns0

# List all the devices to make sure one of them disappeared from the root stack
$ ip link
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
6: veth0@if5: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 96:e8:de:1d:22:e0 brd ff:ff:ff:ff:ff:ff link-netns netns0

```

Once we turn the devices on and assign proper IP addresses, any packet occurring on one of the devices will immediately pop up on its peer device connecting two namespaces. Let's start from the root namespace:

ä¸€æ—¦æˆ‘ä»¬æ‰“å¼€è®¾å¤‡å¹¶åˆ†é…æ­£ç¡®çš„ IP åœ°å€ï¼Œå…¶ä¸­ä¸€ä¸ªè®¾å¤‡ä¸Šå‘ç”Ÿçš„ä»»ä½•æ•°æ®åŒ…éƒ½ä¼šç«‹å³åœ¨å…¶è¿æ¥ä¸¤ä¸ªå‘½åç©ºé—´çš„å¯¹ç­‰è®¾å¤‡ä¸Šå¼¹å‡ºã€‚è®©æˆ‘ä»¬ä»æ ¹å‘½åç©ºé—´å¼€å§‹ï¼š

```bash
$ sudo ip link set veth0 up
$ sudo ip addr add 172.18.0.11/16 dev veth0

```

And continue with the `netns0`:

å¹¶ç»§ç»­ä½¿ç”¨`netns0`ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ip link set lo up  # whoops
$ ip link set ceth0 up
$ ip addr add 172.18.0.10/16 dev ceth0
$ ip link
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
5: ceth0@if6: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
    link/ether 66:2d:24:e3:49:3f brd ff:ff:ff:ff:ff:ff link-netnsid 0

```

![Connecting network namespaces via veth device](http://iximiuz.com/container-networking-is-simple/veth-4000-opt.png)

_Connecting network namespaces via veth device._

_é€šè¿‡ veth è®¾å¤‡è¿æ¥ç½‘ç»œå‘½åç©ºé—´ã€‚_

We are ready to check the connectivity:

æˆ‘ä»¬å‡†å¤‡å¥½æ£€æŸ¥è¿é€šæ€§ï¼š

```bash
# From `netns0`, ping root's veth0
$ ping -c 2 172.18.0.11
PING 172.18.0.11 (172.18.0.11) 56(84) bytes of data.
64 bytes from 172.18.0.11: icmp_seq=1 ttl=64 time=0.038 ms
64 bytes from 172.18.0.11: icmp_seq=2 ttl=64 time=0.040 ms

--- 172.18.0.11 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 58ms
rtt min/avg/max/mdev = 0.038/0.039/0.040/0.001 ms

# Leave `netns0`
$ exit

# From root namespace, ping ceth0
$ ping -c 2 172.18.0.10
PING 172.18.0.10 (172.18.0.10) 56(84) bytes of data.
64 bytes from 172.18.0.10: icmp_seq=1 ttl=64 time=0.073 ms
64 bytes from 172.18.0.10: icmp_seq=2 ttl=64 time=0.046 ms

--- 172.18.0.10 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 3ms
rtt min/avg/max/mdev = 0.046/0.059/0.073/0.015 ms

```

At the same time, if we try to reach any other addresses from the `netns0` namespace, we are not going to succeed:

åŒæ—¶ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•ä» `netns0` å‘½åç©ºé—´è®¿é—®ä»»ä½•å…¶ä»–åœ°å€ï¼Œæˆ‘ä»¬å°†ä¸ä¼šæˆåŠŸï¼š

```bash
# Inside root namespace
$ ip addr show dev eth0
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic noprefixroute eth0
       valid_lft 84057sec preferred_lft 84057sec
    inet6 fe80::5054:ff:fee3:2777/64 scope link
       valid_lft forever preferred_lft forever

# Remember this 10.0.2.15

$ sudo nsenter --net=/var/run/netns/netns0

# Try host's eth0
$ ping 10.0.2.15
connect: Network is unreachable

# Try something from the Internet
$ ping 8.8.8.8
connect: Network is unreachable

```

That's easy to explain, though. There is simply no route in the `netns0` routing table for such packets. The only entry there shows how to reach `172.18.0.0/16` network:

ä¸è¿‡ï¼Œè¿™å¾ˆå®¹æ˜“è§£é‡Šã€‚åœ¨`netns0` è·¯ç”±è¡¨ä¸­æ ¹æœ¬æ²¡æœ‰é’ˆå¯¹æ­¤ç±»æ•°æ®åŒ…çš„è·¯ç”±ã€‚å”¯ä¸€çš„æ¡ç›®æ˜¾ç¤ºäº†å¦‚ä½•è®¿é—®â€œ172.18.0.0/16â€ç½‘ç»œï¼š

```bash
# From `netns0` namespace:
$ ip route
172.18.0.0/16 dev ceth0 proto kernel scope link src 172.18.0.10

```

Linux has a bunch of ways to populate the routing table. One of them is to extract routes from the directly attached network interfaces. Remember, the routing table in `netns0` was empty right after the namespace creation. But then we added the `ceth0` device there and assigned it an IP address `172.18.0.10/16`. Since we were using not a simple IP address, but a combination of the address and the netmask, the network stack managed to extract the routing information from it. Every packet destined to `172.18.0.0/16` network will be sent through `ceth0` device. But any other packets will be discarded. Similarly, there is a new route in the root namespace:

Linux æœ‰å¾ˆå¤šæ–¹æ³•æ¥å¡«å……è·¯ç”±è¡¨ã€‚å…¶ä¸­ä¹‹ä¸€æ˜¯ä»ç›´æ¥è¿æ¥çš„ç½‘ç»œæ¥å£ä¸­æå–è·¯ç”±ã€‚è¯·è®°ä½ï¼Œåœ¨åˆ›å»ºå‘½åç©ºé—´åï¼Œ`netns0` ä¸­çš„è·¯ç”±è¡¨æ˜¯ç©ºçš„ã€‚ä½†éšåæˆ‘ä»¬åœ¨é‚£é‡Œæ·»åŠ äº†â€œceth0â€è®¾å¤‡å¹¶ä¸ºå…¶åˆ†é…äº†ä¸€ä¸ª IP åœ°å€â€œ172.18.0.10/16â€ã€‚ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„ä¸æ˜¯ç®€å•çš„ IP åœ°å€ï¼Œè€Œæ˜¯åœ°å€å’Œç½‘ç»œæ©ç çš„ç»„åˆï¼Œå› æ­¤ç½‘ç»œå †æ ˆè®¾æ³•ä»ä¸­æå–è·¯ç”±ä¿¡æ¯ã€‚æ¯ä¸ªå‘å¾€â€œ172.18.0.0/16â€ç½‘ç»œçš„æ•°æ®åŒ…éƒ½å°†é€šè¿‡â€œceth0â€è®¾å¤‡å‘é€ã€‚ä½†æ˜¯ä»»ä½•å…¶ä»–æ•°æ®åŒ…éƒ½å°†è¢«ä¸¢å¼ƒã€‚åŒæ ·ï¼Œæ ¹å‘½åç©ºé—´ä¸­æœ‰ä¸€ä¸ªæ–°è·¯ç”±ï¼š

```bash
# From `root` namespace:
$ ip route
# ... omitted lines ...
172.18.0.0/16 dev veth0 proto kernel scope link src 172.18.0.11

```

At this point, we are ready to mark our very first question answered. **We know now how to isolate, virtualize, and connect Linux network stacks.**

æ­¤æ—¶ï¼Œæˆ‘ä»¬å·²å‡†å¤‡å¥½æ ‡è®°æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªé—®é¢˜å·²å›ç­”ã€‚ **æˆ‘ä»¬ç°åœ¨çŸ¥é“å¦‚ä½•éš”ç¦»ã€è™šæ‹ŸåŒ–å’Œè¿æ¥ Linux ç½‘ç»œå †æ ˆã€‚**

## Interconnecting containers with virtual network switch (bridge) 

## ç”¨è™šæ‹Ÿç½‘ç»œäº¤æ¢æœºï¼ˆç½‘æ¡¥ï¼‰äº’è¿å®¹å™¨

The whole idea of containerization boils down to efficient resource sharing. I.e. it's uncommon to have a single container per machine. Instead, the goal is to run as many isolated processes in the shared environment as possible. So, what'd happen if we were to place multiple containers on the same host following the `veth` approach from above? Let's add the second _container_:

å®¹å™¨åŒ–çš„æ•´ä¸ªæƒ³æ³•å½’ç»“ä¸ºæœ‰æ•ˆçš„èµ„æºå…±äº«ã€‚ IEã€‚æ¯å°æœºå™¨æœ‰ä¸€ä¸ªå®¹å™¨å¹¶ä¸å¸¸è§ã€‚ç›¸åï¼Œç›®æ ‡æ˜¯åœ¨å…±äº«ç¯å¢ƒä¸­è¿è¡Œå°½å¯èƒ½å¤šçš„éš”ç¦»è¿›ç¨‹ã€‚é‚£ä¹ˆï¼Œå¦‚æœæˆ‘ä»¬æŒ‰ç…§ä¸Šé¢çš„â€œvethâ€æ–¹æ³•å°†å¤šä¸ªå®¹å™¨æ”¾åœ¨åŒä¸€ä¸»æœºä¸Šä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿè®©æˆ‘ä»¬æ·»åŠ ç¬¬äºŒä¸ª _container_ï¼š

```bash
# From root namespace
$ sudo ip netns add netns1
$ sudo ip link add veth1 type veth peer name ceth1
$ sudo ip link set ceth1 netns netns1
$ sudo ip link set veth1 up
$ sudo ip addr add 172.18.0.21/16 dev veth1

$ sudo nsenter --net=/var/run/netns/netns1
$ ip link set lo up
$ ip link set ceth1 up
$ ip addr add 172.18.0.20/16 dev ceth1

```

My favourite part, checking the connectivity:

æˆ‘æœ€å–œæ¬¢çš„éƒ¨åˆ†ï¼Œæ£€æŸ¥è¿æ¥ï¼š

```bash
# From `netns1` we cannot reach the root namespace!
$ ping -c 2 172.18.0.21
PING 172.18.0.21 (172.18.0.21) 56(84) bytes of data.
From 172.18.0.20 icmp_seq=1 Destination Host Unreachable
From 172.18.0.20 icmp_seq=2 Destination Host Unreachable

--- 172.18.0.21 ping statistics ---
2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 55ms
pipe 2

# But there is a route!
$ ip route
172.18.0.0/16 dev ceth1 proto kernel scope link src 172.18.0.20

# Leaving `netns1`
$ exit

# From root namespace we cannot reach the `netns1`
$ ping -c 2 172.18.0.20
PING 172.18.0.20 (172.18.0.20) 56(84) bytes of data.
From 172.18.0.11 icmp_seq=1 Destination Host Unreachable
From 172.18.0.11 icmp_seq=2 Destination Host Unreachable

--- 172.18.0.20 ping statistics ---
2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 23ms
pipe 2

# From `netns0` we CAN reach `veth1`
$ sudo nsenter --net=/var/run/netns/netns0
$ ping -c 2 172.18.0.21
PING 172.18.0.21 (172.18.0.21) 56(84) bytes of data.
64 bytes from 172.18.0.21: icmp_seq=1 ttl=64 time=0.037 ms
64 bytes from 172.18.0.21: icmp_seq=2 ttl=64 time=0.046 ms

--- 172.18.0.21 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 33ms
rtt min/avg/max/mdev = 0.037/0.041/0.046/0.007 ms

# But we still cannot reach `netns1`
$ ping -c 2 172.18.0.20
PING 172.18.0.20 (172.18.0.20) 56(84) bytes of data.
From 172.18.0.10 icmp_seq=1 Destination Host Unreachable
From 172.18.0.10 icmp_seq=2 Destination Host Unreachable

--- 172.18.0.20 ping statistics ---
2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 63ms
pipe 2

```

Whoops! Something is wrong... `netns1` is stuck in limbo. For some reason, it cannot talk to the root and from the root namespace we cannot reach it out too. However, since both containers reside in the same IP network `172.18.0.0/16`, we now can talk to the host's `veth1` from the `netns0` container. Interesting...

å“å‘€ï¼å‡ºäº†ç‚¹é—®é¢˜...... `netns1` é™·å…¥å›°å¢ƒã€‚å‡ºäºæŸç§åŸå› ï¼Œå®ƒæ— æ³•ä¸æ ¹é€šä¿¡ï¼Œå¹¶ä¸”æˆ‘ä»¬ä¹Ÿæ— æ³•ä»æ ¹å‘½åç©ºé—´è®¿é—®å®ƒã€‚ä½†æ˜¯ï¼Œç”±äºä¸¤ä¸ªå®¹å™¨éƒ½ä½äºåŒä¸€ä¸ª IP ç½‘ç»œâ€œ172.18.0.0/16â€ä¸­ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä»â€œnetns0â€å®¹å™¨ä¸­ä¸ä¸»æœºçš„â€œveth1â€é€šä¿¡ã€‚æœ‰è¶£çš„...

Well, it took me some time to figure it out, but apparently we are facing the clash of routes. Let's inspect the routing table in the root namespace:

å¥½å§ï¼Œæˆ‘èŠ±äº†ä¸€äº›æ—¶é—´æ‰å¼„æ˜ç™½ï¼Œä½†æ˜¾ç„¶æˆ‘ä»¬æ­£é¢ä¸´è·¯çº¿å†²çªã€‚è®©æˆ‘ä»¬æ£€æŸ¥æ ¹å‘½åç©ºé—´ä¸­çš„è·¯ç”±è¡¨ï¼š

```bash
$ ip route
# ... omitted lines ...
172.18.0.0/16 dev veth0 proto kernel scope link src 172.18.0.11
172.18.0.0/16 dev veth1 proto kernel scope link src 172.18.0.21

```

Even though after adding the second `veth` pair, root's network stack learned the new route `172.18.0.0/16 dev veth1 proto kernel scope link src 172.18.0.21`, there already was an existing route for exactly the same network. When the second container tries to ping `veth1` device, the first route is being selected breaking the connectivity. If we were to delete the first route `sudo ip route delete 172.18.0.0/16 dev veth0 proto kernel scope link src 172.18.0.11` and recheck the connectivity, the situation would turn into a mirrored case. I.e. the connectivity of the `netns1` would be restored, but `netns0` would be in limbo.

å³ä½¿åœ¨æ·»åŠ ç¬¬äºŒä¸ª `veth` å¯¹åï¼Œroot çš„ç½‘ç»œå †æ ˆå­¦ä¹ åˆ°äº†æ–°è·¯ç”± `172.18.0.0/16 dev veth1 proto kernel scope link src 172.18.0.21`ï¼Œå·²ç»å­˜åœ¨å®Œå…¨ç›¸åŒç½‘ç»œçš„ç°æœ‰è·¯ç”±ã€‚å½“ç¬¬äºŒä¸ªå®¹å™¨å°è¯• ping 'veth1' è®¾å¤‡æ—¶ï¼Œç¬¬ä¸€ä¸ªè·¯ç”±è¢«é€‰æ‹©ç ´åäº†è¿æ¥ã€‚å¦‚æœæˆ‘ä»¬åˆ é™¤ç¬¬ä¸€æ¡è·¯ç”±`sudo ip route delete 172.18.0.0/16 dev veth0 proto kernel scope link src 172.18.0.11`å¹¶é‡æ–°æ£€æŸ¥è¿é€šæ€§ï¼Œæƒ…å†µå°±ä¼šå˜æˆé•œåƒæƒ…å†µã€‚ IEã€‚ `netns1` çš„è¿æ¥å°†æ¢å¤ï¼Œä½† `netns0` å°†å¤„äºä¸ç¡®å®šçŠ¶æ€ã€‚

![Connecting multiple network namespaces with a bridge](http://iximiuz.com/container-networking-is-simple/route-clash-4000-opt.png)

Well, I believe if we selected another IP network for `netns1`, everything would work. However, multiple containers sitting in one IP network is a legitimate use case. Thus, we need to adjust the `veth` approach somehow...

å¥½å§ï¼Œæˆ‘ç›¸ä¿¡å¦‚æœæˆ‘ä»¬ä¸º `netns1` é€‰æ‹©å¦ä¸€ä¸ª IP ç½‘ç»œï¼Œä¸€åˆ‡éƒ½ä¼šæ­£å¸¸ã€‚ä½†æ˜¯ï¼Œä½äºä¸€ä¸ª IP ç½‘ç»œä¸­çš„å¤šä¸ªå®¹å™¨æ˜¯ä¸€ç§åˆæ³•ç”¨ä¾‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä»¥æŸç§æ–¹å¼è°ƒæ•´ `veth` æ–¹æ³•......

Behold the Linux bridge - yet another virtualized network facility! The Linux bridge behaves like a network switch. It forwards packets between interfaces that are connected to it. And since it's a switch, it does it on the L2 (i.e. Ethernet) level. 

çœ‹çœ‹ Linux ç½‘æ¡¥â€”â€”åˆä¸€ä¸ªè™šæ‹ŸåŒ–çš„ç½‘ç»œè®¾æ–½ï¼ Linux ç½‘æ¡¥çš„è¡Œä¸ºç±»ä¼¼äºç½‘ç»œäº¤æ¢æœºã€‚å®ƒåœ¨è¿æ¥åˆ°å®ƒçš„æ¥å£ä¹‹é—´è½¬å‘æ•°æ®åŒ…ã€‚å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªäº¤æ¢æœºï¼Œæ‰€ä»¥å®ƒåœ¨ L2ï¼ˆå³ä»¥å¤ªç½‘ï¼‰çº§åˆ«ä¸Šè¿›è¡Œã€‚

Let's try to play with our new toy. But first, we need to clean up the existing setup because some of the configurational changes we've made so far aren't really needed anymore. Removing network namespaces would suffice:

è®©æˆ‘ä»¬è¯•ç€ç©æˆ‘ä»¬çš„æ–°ç©å…·ã€‚ä½†é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ¸…ç†ç°æœ‰è®¾ç½®ï¼Œå› ä¸ºæˆ‘ä»¬ç›®å‰æ‰€åšçš„ä¸€äº›é…ç½®æ›´æ”¹å®é™…ä¸Šä¸å†éœ€è¦äº†ã€‚åˆ é™¤ç½‘ç»œå‘½åç©ºé—´å°±è¶³å¤Ÿäº†ï¼š

```bash
$ sudo ip netns delete netns0
$ sudo ip netns delete netns1

# But if you still have some leftovers...
$ sudo ip link delete veth0
$ sudo ip link delete ceth0
$ sudo ip link delete veth1
$ sudo ip link delete ceth1

```

Quickly re-create two containers. Notice, we don't assign any IP address to the new `veth0` and `veth1` devices:

å¿«é€Ÿé‡æ–°åˆ›å»ºä¸¤ä¸ªå®¹å™¨ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ²¡æœ‰ä¸ºæ–°çš„ `veth0` å’Œ `veth1` è®¾å¤‡åˆ†é…ä»»ä½• IP åœ°å€ï¼š

```bash
$ sudo ip netns add netns0
$ sudo ip link add veth0 type veth peer name ceth0
$ sudo ip link set veth0 up
$ sudo ip link set ceth0 netns netns0

$ sudo nsenter --net=/var/run/netns/netns0
$ ip link set lo up
$ ip link set ceth0 up
$ ip addr add 172.18.0.10/16 dev ceth0
$ exit

$ sudo ip netns add netns1
$ sudo ip link add veth1 type veth peer name ceth1
$ sudo ip link set veth1 up
$ sudo ip link set ceth1 netns netns1

$ sudo nsenter --net=/var/run/netns/netns1
$ ip link set lo up
$ ip link set ceth1 up
$ ip addr add 172.18.0.20/16 dev ceth1
$ exit

```

Make sure there is no new routes on the host:

ç¡®ä¿ä¸»æœºä¸Šæ²¡æœ‰æ–°è·¯ç”±ï¼š

```bash
$ ip route
default via 10.0.2.2 dev eth0 proto dhcp metric 100
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100

```

And finally, create the bridge interface:

æœ€åï¼Œåˆ›å»ºæ¡¥æ¥å£ï¼š

```bash
$ sudo ip link add br0 type bridge
$ sudo ip link set br0 up

```

Now, attach `veth0` and `veth1` ends to the bridge:

ç°åœ¨ï¼Œå°† `veth0` å’Œ `veth1` ç«¯é™„åŠ åˆ°æ¡¥ä¸Šï¼š

```bash
$ sudo ip link set veth0 master br0
$ sudo ip link set veth1 master br0
```

![Setting up routing between multiple network namespaces](http://iximiuz.com/container-networking-is-simple/bridge-4000-opt.png)

...and check the connectivity between containers:

...å¹¶æ£€æŸ¥å®¹å™¨ä¹‹é—´çš„è¿æ¥ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ping -c 2 172.18.0.20
PING 172.18.0.20 (172.18.0.20) 56(84) bytes of data.
64 bytes from 172.18.0.20: icmp_seq=1 ttl=64 time=0.259 ms
64 bytes from 172.18.0.20: icmp_seq=2 ttl=64 time=0.051 ms

--- 172.18.0.20 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 2ms
rtt min/avg/max/mdev = 0.051/0.155/0.259/0.104 ms

```

```bash
$ sudo nsenter --net=/var/run/netns/netns1
$ ping -c 2 172.18.0.10
PING 172.18.0.10 (172.18.0.10) 56(84) bytes of data.
64 bytes from 172.18.0.10: icmp_seq=1 ttl=64 time=0.037 ms
64 bytes from 172.18.0.10: icmp_seq=2 ttl=64 time=0.089 ms

--- 172.18.0.10 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 36ms
rtt min/avg/max/mdev = 0.037/0.063/0.089/0.026 ms

```

Lovely! Everything works great. With this new approach, we haven't been configuring `veth0` and `veth1` at all. The only two IP addresses we assigned were on the `ceth0` and `ceth1` ends. But since both of them are on the same Ethernet segment (remember, we connected them to the virtual switch), there is connectivity on the L2 level:

è¿·äººçš„ï¼ä¸€åˆ‡éƒ½å¾ˆå¥½ã€‚ä½¿ç”¨è¿™ç§æ–°æ–¹æ³•ï¼Œæˆ‘ä»¬æ ¹æœ¬æ²¡æœ‰é…ç½® `veth0` å’Œ `veth1`ã€‚æˆ‘ä»¬åˆ†é…çš„ä»…æœ‰çš„ä¸¤ä¸ª IP åœ°å€ä½äºâ€œceth0â€å’Œâ€œceth1â€ç«¯ã€‚ä½†æ˜¯ç”±äºå®ƒä»¬éƒ½åœ¨åŒä¸€ä¸ªä»¥å¤ªç½‘æ®µä¸Šï¼ˆè¯·è®°ä½ï¼Œæˆ‘ä»¬å°†å®ƒä»¬è¿æ¥åˆ°è™šæ‹Ÿäº¤æ¢æœºï¼‰ï¼Œå› æ­¤åœ¨ L2 çº§åˆ«å­˜åœ¨è¿æ¥ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ip neigh
172.18.0.20 dev ceth0 lladdr 6e:9c:ae:02:60:de STALE
$ exit

$ sudo nsenter --net=/var/run/netns/netns1
$ ip neigh
172.18.0.10 dev ceth1 lladdr 66:f3:8c:75:09:29 STALE
$ exit

```

Congratulations, we learned how to **turn containers into friendly neighbors, prevent them from interfering, but keep the connectivity.**

æ­å–œï¼Œæˆ‘ä»¬å­¦ä¼šäº†å¦‚ä½•**å°†å®¹å™¨å˜æˆå‹å¥½çš„é‚»å±…ï¼Œé˜²æ­¢å®ƒä»¬å¹²æ‰°ï¼Œä½†ä¿æŒè¿æ¥ã€‚**

## Reaching out to the outside world (IP routing and masquerading)

## ä¸å¤–ç•Œè”ç³»ï¼ˆIP è·¯ç”±å’Œä¼ªè£…ï¼‰

Our containers can talk to each other. But can they talk to the host, i.e. the root namespace?

æˆ‘ä»¬çš„å®¹å™¨å¯ä»¥ç›¸äº’äº¤è°ˆã€‚ä½†æ˜¯å®ƒä»¬å¯ä»¥ä¸ä¸»æœºï¼ˆå³æ ¹å‘½åç©ºé—´ï¼‰é€šä¿¡å—ï¼Ÿ

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ping 10.0.2.15  # eth0 address
connect: Network is unreachable

```

That's kind of obvious, there is simply no route for that in `netns0`:

è¿™å¾ˆæ˜æ˜¾ï¼Œåœ¨ `netns0` ä¸­æ ¹æœ¬æ²¡æœ‰è·¯å¾„ï¼š

```bash
$ ip route
172.18.0.0/16 dev ceth0 proto kernel scope link src 172.18.0.10

```

The root namespace cannot talk to containers either:

æ ¹å‘½åç©ºé—´ä¹Ÿä¸èƒ½ä¸å®¹å™¨é€šä¿¡ï¼š

```bash
# Use exit to leave `netns0` first:
$ ping -c 2 172.18.0.10
PING 172.18.0.10 (172.18.0.10) 56(84) bytes of data.
From 213.51.1.123 icmp_seq=1 Destination Net Unreachable
From 213.51.1.123 icmp_seq=2 Destination Net Unreachable

--- 172.18.0.10 ping statistics ---
2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 3ms

$ ping -c 2 172.18.0.20
PING 172.18.0.20 (172.18.0.20) 56(84) bytes of data.
From 213.51.1.123 icmp_seq=1 Destination Net Unreachable
From 213.51.1.123 icmp_seq=2 Destination Net Unreachable

--- 172.18.0.20 ping statistics ---
2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 3ms

```

To establish the connectivity between the root and container namespaces, we need to assign the IP address to the bridge network interface:

ä¸ºäº†åœ¨æ ¹å‘½åç©ºé—´å’Œå®¹å™¨å‘½åç©ºé—´ä¹‹é—´å»ºç«‹è¿æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¡¥æ¥ç½‘ç»œæ¥å£åˆ†é… IP åœ°å€ï¼š

```bash
$ sudo ip addr add 172.18.0.1/16 dev br0

```

Once we assigned the IP address to the bridge interface, we got a route on the host routing table:

ä¸€æ—¦æˆ‘ä»¬ä¸ºç½‘æ¡¥æ¥å£åˆ†é…äº† IP åœ°å€ï¼Œæˆ‘ä»¬å°±åœ¨ä¸»æœºè·¯ç”±è¡¨ä¸Šå¾—åˆ°äº†ä¸€æ¡è·¯ç”±ï¼š

```bash
$ ip route
# ... omitted lines ...
172.18.0.0/16 dev br0 proto kernel scope link src 172.18.0.1

$ ping -c 2 172.18.0.10
PING 172.18.0.10 (172.18.0.10) 56(84) bytes of data.
64 bytes from 172.18.0.10: icmp_seq=1 ttl=64 time=0.036 ms
64 bytes from 172.18.0.10: icmp_seq=2 ttl=64 time=0.049 ms

--- 172.18.0.10 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 11ms
rtt min/avg/max/mdev = 0.036/0.042/0.049/0.009 ms

$ ping -c 2 172.18.0.20
PING 172.18.0.20 (172.18.0.20) 56(84) bytes of data.
64 bytes from 172.18.0.20: icmp_seq=1 ttl=64 time=0.059 ms
64 bytes from 172.18.0.20: icmp_seq=2 ttl=64 time=0.056 ms

--- 172.18.0.20 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 4ms
rtt min/avg/max/mdev = 0.056/0.057/0.059/0.007 ms

```

The container probably also got an ability to ping the bridge interface, but they still cannot reach out to host's `eth0`. We need to add the default route for containers:

å®¹å™¨å¯èƒ½ä¹Ÿæœ‰èƒ½åŠ› ping æ¡¥æ¥æ¥å£ï¼Œä½†å®ƒä»¬ä»ç„¶æ— æ³•è®¿é—®ä¸»æœºçš„â€œeth0â€ã€‚æˆ‘ä»¬éœ€è¦ä¸ºå®¹å™¨æ·»åŠ é»˜è®¤è·¯ç”±ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ip route add default via 172.18.0.1
$ ping -c 2 10.0.2.15
PING 10.0.2.15 (10.0.2.15) 56(84) bytes of data.
64 bytes from 10.0.2.15: icmp_seq=1 ttl=64 time=0.036 ms
64 bytes from 10.0.2.15: icmp_seq=2 ttl=64 time=0.053 ms

--- 10.0.2.15 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 14ms
rtt min/avg/max/mdev = 0.036/0.044/0.053/0.010 ms

# And repeat the change for `netns1`

```

This change basically turned the host machine into a router and the bridge interface became the default gateway for the containers.

è¿™ä¸€å˜åŒ–åŸºæœ¬ä¸Šå°†ä¸»æœºå˜æˆäº†è·¯ç”±å™¨ï¼Œæ¡¥æ¥æ¥å£æˆä¸ºå®¹å™¨çš„é»˜è®¤ç½‘å…³ã€‚

![Using bridge as a gateway](http://iximiuz.com/container-networking-is-simple/router-4000-opt.png)

Perfect, we connected containers with the root namespace. Now, let's try to connect them to the outside world. By default, the packet forwarding (i.e. the router functionality) is disabled in Linux. We need to turn it on:

å®Œç¾ï¼Œæˆ‘ä»¬å°†å®¹å™¨ä¸æ ¹å‘½åç©ºé—´è¿æ¥èµ·æ¥ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•å°†å®ƒä»¬è¿æ¥åˆ°å¤–éƒ¨ä¸–ç•Œã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒLinux ä¸­ç¦ç”¨æ•°æ®åŒ…è½¬å‘ï¼ˆå³è·¯ç”±å™¨åŠŸèƒ½ï¼‰ã€‚æˆ‘ä»¬éœ€è¦å¼€å¯å®ƒï¼š

```bash
# In the root namespace
sudo bash -c 'echo 1 > /proc/sys/net/ipv4/ip_forward'

```

Again, my favourite part - checking the connectivity:

å†æ¬¡ï¼Œæˆ‘æœ€å–œæ¬¢çš„éƒ¨åˆ† - æ£€æŸ¥è¿æ¥ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ping 8.8.8.8
# hangs indefinitely long for me...

```

Well, still doesn't work. What have we missed? If the container were to sends packets to the outside world, the destination server would not be able to send packets back to the container because the container's IP address is private. I.e. the routing rules for that particular IP are known only to the local network. And lots of the containers in the world share exactly the same private IP address `172.18.0.10`. The solution to this problem is called the [Network address translation (NAT)](https://en.wikipedia.org/wiki/Network_address_translation). Before going to the external network, packets originated by the containers will get their source IP addresses replaced with the host's external interface address. The host also will track all the existing mappings and on arrival, it'll be restoring the IP addresses before forwarding packets back to the containers. Sounds complicated, but I have good news for you! Thanks to [iptables](http://iximiuz.com/en/posts/laymans-iptables-101/) module, we need only a single command to make it happen:

å—¯ï¼Œè¿˜æ˜¯ä¸è¡Œã€‚æˆ‘ä»¬é”™è¿‡äº†ä»€ä¹ˆï¼Ÿå¦‚æœå®¹å™¨å°†æ•°æ®åŒ…å‘é€åˆ°å¤–éƒ¨ä¸–ç•Œï¼Œç›®æ ‡æœåŠ¡å™¨å°†æ— æ³•å°†æ•°æ®åŒ…å‘é€å›å®¹å™¨ï¼Œå› ä¸ºå®¹å™¨çš„ IP åœ°å€æ˜¯ç§æœ‰çš„ã€‚ IEã€‚è¯¥ç‰¹å®š IP çš„è·¯ç”±è§„åˆ™åªæœ‰æœ¬åœ°ç½‘ç»œçŸ¥é“ã€‚ä¸–ç•Œä¸Šè®¸å¤šå®¹å™¨å…±äº«å®Œå…¨ç›¸åŒçš„ç§æœ‰ IP åœ°å€â€œ172.18.0.10â€ã€‚æ­¤é—®é¢˜çš„è§£å†³æ–¹æ¡ˆç§°ä¸º [ç½‘ç»œåœ°å€è½¬æ¢ (NAT)](https://en.wikipedia.org/wiki/Network_address_translation)ã€‚åœ¨è¿›å…¥å¤–éƒ¨ç½‘ç»œä¹‹å‰ï¼Œç”±å®¹å™¨å‘èµ·çš„æ•°æ®åŒ…ä¼šå°†å…¶æº IP åœ°å€æ›¿æ¢ä¸ºä¸»æœºçš„å¤–éƒ¨æ¥å£åœ°å€ã€‚ä¸»æœºè¿˜å°†è·Ÿè¸ªæ‰€æœ‰ç°æœ‰æ˜ å°„ï¼Œå¹¶åœ¨åˆ°è¾¾æ—¶æ¢å¤ IP åœ°å€ï¼Œç„¶åå°†æ•°æ®åŒ…è½¬å‘å›å®¹å™¨ã€‚å¬èµ·æ¥å¾ˆå¤æ‚ï¼Œä½†æˆ‘æœ‰ä¸ªå¥½æ¶ˆæ¯è¦å‘Šè¯‰ä½ ï¼æ„Ÿè°¢ [iptables](http://iximiuz.com/en/posts/laymans-iptables-101/) æ¨¡å—ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸€ä¸ªå‘½ä»¤å°±å¯ä»¥å®ç°ï¼š

```bash
$ sudo iptables -t nat -A POSTROUTING -s 172.18.0.0/16 !-o br0 -j MASQUERADE

```

The command is fairly simple. We are adding a new rule to the `nat` table of the `POSTROUTING` chain asking to masquerade all the packets originated in `172.18.0.0/16` network, but not by the bridge interface.

å‘½ä»¤ç›¸å½“ç®€å•ã€‚æˆ‘ä»¬æ­£åœ¨å‘`POSTROUTING`é“¾çš„`nat`è¡¨æ·»åŠ ä¸€ä¸ªæ–°è§„åˆ™ï¼Œè¦æ±‚ä¼ªè£…æ‰€æœ‰æºè‡ª`172.18.0.0/16`ç½‘ç»œçš„æ•°æ®åŒ…ï¼Œä½†ä¸æ˜¯æ¥è‡ªç½‘æ¡¥æ¥å£ã€‚

Check the connectivity:

æ£€æŸ¥è¿é€šæ€§ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ ping -c 2 8.8.8.8
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=61 time=43.2 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=61 time=36.8 ms

--- 8.8.8.8 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 2ms
rtt min/avg/max/mdev = 36.815/40.008/43.202/3.199 ms

```

Beware that we're following _by default - allow_ strategy which might be quite dangerous in a real-world setup. The host's default iptables policy is `ACCEPT` for every chain:

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ­£åœ¨éµå¾ª _by default - allow_ ç­–ç•¥ï¼Œè¿™åœ¨å®é™…è®¾ç½®ä¸­å¯èƒ½éå¸¸å±é™©ã€‚å¯¹äºæ¯ä¸ªé“¾ï¼Œä¸»æœºçš„é»˜è®¤ iptables ç­–ç•¥æ˜¯ `ACCEPT`ï¼š

```bash
sudo iptables -S
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT

```

As a good example, Docker, instead, restricts everything by default and then enables routing for only known paths.

ä½œä¸ºä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼ŒDocker åœ¨é»˜è®¤æƒ…å†µä¸‹é™åˆ¶ä¸€åˆ‡ï¼Œç„¶ååªä¸ºå·²çŸ¥è·¯å¾„å¯ç”¨è·¯ç”±ã€‚

Click here to see Docker iptables rules.

å•å‡»æ­¤å¤„æŸ¥çœ‹ Docker iptables è§„åˆ™ã€‚

The following are the dumped rules generated by the Docker daemon on a _CentOS 8_ machine with single container exposed on port 5005:

ä»¥ä¸‹æ˜¯ _CentOS 8_ æœºå™¨ä¸Šçš„ Docker å®ˆæŠ¤ç¨‹åºç”Ÿæˆçš„è½¬å‚¨è§„åˆ™ï¼Œå•ä¸ªå®¹å™¨æš´éœ²åœ¨ç«¯å£ 5005 ä¸Šï¼š

```bash
$ sudo iptables -t filter --list-rules
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
-A FORWARD -j DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -i docker0 !-o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A DOCKER -d 172.17.0.2/32 !-i docker0 -o docker0 -p tcp -m tcp --dport 5000 -j ACCEPT
-A DOCKER-ISOLATION-STAGE-1 -i docker0 !-o docker0 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN

$ sudo iptables -t nat --list-rules
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P POSTROUTING ACCEPT
-P OUTPUT ACCEPT
-N DOCKER
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -s 172.17.0.0/16 !-o docker0 -j MASQUERADE
-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 5000 -j MASQUERADE
-A OUTPUT !-d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A DOCKER -i docker0 -j RETURN
-A DOCKER !-i docker0 -p tcp -m tcp --dport 5005 -j DNAT --to-destination 172.17.0.2:5000

$ sudo iptables -t mangle --list-rules
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT

$ sudo iptables -t raw --list-rules
-P PREROUTING ACCEPT
-P OUTPUT ACCEPT

```

## Letting the outside world reach out to containers (port publishing)

## è®©å¤–ç•Œæ¥è§¦åˆ°å®¹å™¨ï¼ˆç«¯å£å‘å¸ƒï¼‰

It's a known practice to _publish_ container ports to some (or all) of the host's interfaces. But what does _port publishing_ really mean?

å°†å®¹å™¨ç«¯å£_å‘å¸ƒ_åˆ°ä¸»æœºçš„æŸäº›ï¼ˆæˆ–å…¨éƒ¨ï¼‰æ¥å£æ˜¯ä¸€ç§ä¼—æ‰€å‘¨çŸ¥çš„åšæ³•ã€‚ä½†æ˜¯ _port å‘å¸ƒ_ åˆ°åº•æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

Imagine we have a server running inside a container:

æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªåœ¨å®¹å™¨å†…è¿è¡Œçš„æœåŠ¡å™¨ï¼š

```bash
$ sudo nsenter --net=/var/run/netns/netns0
$ python3 -m http.server --bind 172.18.0.10 5000

```

If we try to send an HTTP request to this server process from the host, everything will work (well, there is a connectivity between root namespace and all the container interfaces, why wouldn't it?):

å¦‚æœæˆ‘ä»¬å°è¯•ä»ä¸»æœºå‘æ­¤æœåŠ¡å™¨è¿›ç¨‹å‘é€ HTTP è¯·æ±‚ï¼Œä¸€åˆ‡éƒ½ä¼šæ­£å¸¸å·¥ä½œï¼ˆå¥½å§ï¼Œæ ¹å‘½åç©ºé—´å’Œæ‰€æœ‰å®¹å™¨æ¥å£ä¹‹é—´å­˜åœ¨è¿æ¥ï¼Œä¸ºä»€ä¹ˆä¸å‘¢ï¼Ÿï¼‰ï¼š

```bash
# From root namespace
$ curl 172.18.0.10:5000
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
# ... omitted lines ...

```

However, if we were to access this server from the outside world, what IP address would we use? The only IP address we might know is the host's external interface address `eth0`:

ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä»å¤–éƒ¨è®¿é—®è¿™ä¸ªæœåŠ¡å™¨ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä»€ä¹ˆ IP åœ°å€ï¼Ÿæˆ‘ä»¬å¯èƒ½çŸ¥é“çš„å”¯ä¸€ IP åœ°å€æ˜¯ä¸»æœºçš„å¤–éƒ¨æ¥å£åœ°å€â€œeth0â€ï¼š

```bash
$ curl 10.0.2.15:5000
curl: (7) Failed to connect to 10.0.2.15 port 5000: Connection refused

```

Thus, we need to find a way to forward any packets arriving at port 5000 on the host's `eth0` interface to `172.18.0.10:5000` destination. Or, in other words, we need to _publish_ the container's port 5000 on the host's `eth0` interface. iptables to the rescue!

å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•å°†ä»»ä½•åˆ°è¾¾ä¸»æœºâ€œeth0â€æ¥å£ä¸Šç«¯å£ 5000 çš„æ•°æ®åŒ…è½¬å‘åˆ°â€œ172.18.0.10:5000â€ç›®çš„åœ°ã€‚æˆ–è€…ï¼Œæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ä¸»æœºçš„ eth0 æ¥å£ä¸Š_å‘å¸ƒ_å®¹å™¨çš„ç«¯å£ 5000ã€‚ iptables æ¥æ•‘æ´ï¼

```bash
# External traffic
sudo iptables -t nat -A PREROUTING -d 10.0.2.15 -p tcp -m tcp --dport 5000 -j DNAT --to-destination 172.18.0.10:5000

# Local traffic (since it doesn't pass the PREROUTING chain)
sudo iptables -t nat -A OUTPUT -d 10.0.2.15 -p tcp -m tcp --dport 5000 -j DNAT --to-destination 172.18.0.10:5000

```

Additionally, we need to enable [iptables intercepting traffic over bridged networks](https://github.com/omribahumi/libvirt_metadata_api/pull/4/files):

æ­¤å¤–ï¼Œæˆ‘ä»¬éœ€è¦å¯ç”¨ [iptables æ‹¦æˆªæ¡¥æ¥ç½‘ç»œä¸Šçš„æµé‡](https://github.com/omribahumi/libvirt_metadata_api/pull/4/files)ï¼š

```bash
sudo modprobe br_netfilter

```

Testing time!

æµ‹è¯•æ—¶é—´ï¼

```bash
curl 10.0.2.15:5000
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
# ... omitted lines ...
```

## Understanding Docker network drivers

## äº†è§£ Docker ç½‘ç»œé©±åŠ¨ç¨‹åº

Ok, sir, what can we do with all this useless knowledge? For instance, we could try to understand some of the [Docker network modes](https://docs.docker.com/network/#network-drivers)! 

å¥½çš„ï¼Œå…ˆç”Ÿï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™äº›æ— ç”¨çš„çŸ¥è¯†åšä»€ä¹ˆï¼Ÿä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•äº†è§£ä¸€äº›[Docker ç½‘ç»œæ¨¡å¼](https://docs.docker.com/network/#network-drivers)ï¼

Let's start from the `--network host` mode. Try to compare the output of the following commands `ip link` and `sudo docker run -it --rm --network host alpine ip link`. Surprise, surprise, they are exactly the same! I.e. in the `host` mode, Docker simply doesn't use the network namespace isolation and containers work in the root network namespace and share the network stack with the host machine.

è®©æˆ‘ä»¬ä»`--network host`æ¨¡å¼å¼€å§‹ã€‚å°è¯•æ¯”è¾ƒä»¥ä¸‹å‘½ä»¤ `ip link` å’Œ `sudo docker run -it --rm --network host alpine ip link` çš„è¾“å‡ºã€‚æƒŠå–œï¼ŒæƒŠå–œï¼Œå®ƒä»¬ä¸€æ¨¡ä¸€æ ·ï¼ IEã€‚åœ¨`host` æ¨¡å¼ä¸‹ï¼ŒDocker æ ¹æœ¬ä¸ä½¿ç”¨ç½‘ç»œå‘½åç©ºé—´éš”ç¦»ï¼Œå®¹å™¨åœ¨æ ¹ç½‘ç»œå‘½åç©ºé—´ä¸­å·¥ä½œå¹¶ä¸ä¸»æœºå…±äº«ç½‘ç»œå †æ ˆã€‚

The next mode to inspect is `--network none`. The output of the `sudo docker run -it --rm --network none alpine ip link` command shows only a single loopback network interface. It's very similar to our observations of the freshly created network namespace. I.e. before the point where we were adding any `veth` devices.

ä¸‹ä¸€ä¸ªè¦æ£€æŸ¥çš„æ¨¡å¼æ˜¯`--network none`ã€‚ `sudo docker run -it --rm --network none alpine ip link` å‘½ä»¤çš„è¾“å‡ºä»…æ˜¾ç¤ºä¸€ä¸ªç¯å›ç½‘ç»œæ¥å£ã€‚è¿™ä¸æˆ‘ä»¬å¯¹æ–°åˆ›å»ºçš„ç½‘ç»œå‘½åç©ºé—´çš„è§‚å¯Ÿéå¸¸ç›¸ä¼¼ã€‚ IEã€‚åœ¨æˆ‘ä»¬æ·»åŠ ä»»ä½•â€œvethâ€è®¾å¤‡ä¹‹å‰ã€‚

Last but not least, the `--network bridge` (the default) mode. Well, it's exactly what we've been trying to reproduce in this whole article. I encourage you to play with `ip` and `iptables` commands and inspect the network stack from the host and containers point of view.

æœ€åä½†å¹¶éæœ€ä¸é‡è¦çš„æ˜¯ï¼Œ`--network bridge`ï¼ˆé»˜è®¤ï¼‰æ¨¡å¼ã€‚å—¯ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬åœ¨æ•´ç¯‡æ–‡ç« ä¸­ä¸€ç›´è¯•å›¾é‡ç°çš„å†…å®¹ã€‚æˆ‘é¼“åŠ±ä½ ä½¿ç”¨ `ip` å’Œ `iptables` å‘½ä»¤ï¼Œå¹¶ä»ä¸»æœºå’Œå®¹å™¨çš„è§’åº¦æ£€æŸ¥ç½‘ç»œå †æ ˆã€‚

## Bonus: rootless containers and networking

## å¥–åŠ±ï¼šæ— æ ¹å®¹å™¨å’Œç½‘ç»œ

One of the nice features of `podman` container manager is its focus on rootless containers. However, as you probably noticed, we used a lot of `sudo` escalations in this article. I.e. it's impossible to configure the network without root privileges. [Podman's approach](https://www.redhat.com/sysadmin/container-networking-podman) to rootful networking is very close to docker. But when it comes to rootless containers, podman relies on [slirp4netns](https://github.com/rootless-containers/slirp4netns) project:

`podman` å®¹å™¨ç®¡ç†å™¨çš„ä¸€ä¸ªå¾ˆå¥½çš„ç‰¹æ€§æ˜¯å®ƒä¸“æ³¨äºæ— æ ¹å®¹å™¨ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­ä½¿ç”¨äº†å¾ˆå¤š `sudo` å‡çº§ã€‚ IEã€‚æ²¡æœ‰rootæƒé™å°±ä¸å¯èƒ½é…ç½®ç½‘ç»œã€‚  [Podman çš„åšæ³•](https://www.redhat.com/sysadmin/container-networking-podman) å¯¹ rootful ç½‘ç»œéå¸¸æ¥è¿‘ dockerã€‚ä½†æ˜¯è¯´åˆ°æ— æ ¹å®¹å™¨ï¼Œpodman ä¾èµ–äº [slirp4netns](https://github.com/rootless-containers/slirp4netns) é¡¹ç›®ï¼š

> Starting with Linux 3.8, unprivileged users can create network\_namespaces(7) along with user\_namespaces(7). However, unprivileged network namespaces had not been very useful, because creating veth(4) pairs across the host and network namespaces still requires the root privileges. (i.e. No internet connection)

> ä» Linux 3.8 å¼€å§‹ï¼Œéç‰¹æƒç”¨æˆ·å¯ä»¥åˆ›å»º network\_namespaces(7) å’Œ user\_namespaces(7)ã€‚ç„¶è€Œï¼Œéç‰¹æƒç½‘ç»œå‘½åç©ºé—´å¹¶ä¸æ˜¯å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºåœ¨ä¸»æœºå’Œç½‘ç»œå‘½åç©ºé—´ä¹‹é—´åˆ›å»º veth(4) å¯¹ä»ç„¶éœ€è¦ root æƒé™ã€‚ ï¼ˆå³æ²¡æœ‰äº’è”ç½‘è¿æ¥ï¼‰

> slirp4netns allows connecting a network namespace to the Internet in a completely unprivileged way, by connecting a TAP device in a network namespace to the usermode TCP/IP stack ("slirp").

> slirp4netns å…è®¸ä»¥å®Œå…¨æ— ç‰¹æƒçš„æ–¹å¼å°†ç½‘ç»œå‘½åç©ºé—´è¿æ¥åˆ° Internetï¼Œæ–¹æ³•æ˜¯å°†ç½‘ç»œå‘½åç©ºé—´ä¸­çš„ TAP è®¾å¤‡è¿æ¥åˆ°ç”¨æˆ·æ¨¡å¼ TCP/IP å †æ ˆï¼ˆâ€œslirpâ€ï¼‰ã€‚

The rootless networking [is quite limited](https://www.redhat.com/sysadmin/container-networking-podman): "technically, the container itself does not have an IP address, because without root privileges, network device association cannot be achieved. Moreover, pinging from a rootless container does not work because it lacks the CAP\_NET\_RAW security capability that the ping command requires." But it's still better than no connectivity at all.

æ— æ ¹ç½‘ç»œ[ç›¸å½“æœ‰é™](https://www.redhat.com/sysadmin/container-networking-podman)ï¼šâ€œä»æŠ€æœ¯ä¸Šè®²ï¼Œå®¹å™¨æœ¬èº«æ²¡æœ‰IPåœ°å€ï¼Œå› ä¸ºæ²¡æœ‰rootæƒé™ï¼Œç½‘ç»œè®¾å¤‡å…³è”ä¸èƒ½å®ç°ã€‚æ­¤å¤–ï¼Œä»æ— æ ¹å®¹å™¨ ping ä¸èµ·ä½œç”¨ï¼Œå› ä¸ºå®ƒç¼ºå°‘ ping å‘½ä»¤æ‰€éœ€çš„ CAP\_NET\_RAW å®‰å…¨åŠŸèƒ½ã€‚â€ä½†è¿™ä»ç„¶æ¯”å®Œå…¨æ²¡æœ‰è¿æ¥è¦å¥½ã€‚

## Conclusion

##  ç»“è®º

The considered in this article approach to organizing container networking is only one of the possible ways (well, probably the most widely used one). There are many more other ways, implemented as official or 3rd party plugins, but all of them heavily rely on [Linux network virtualization facilities](https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/). Thus, containerization can fairly be regarded as virtualization technology.

æœ¬æ–‡ä¸­è€ƒè™‘çš„ç»„ç»‡å®¹å™¨ç½‘ç»œçš„æ–¹æ³•åªæ˜¯å…¶ä¸­ä¸€ç§å¯èƒ½çš„æ–¹æ³•ï¼ˆå—¯ï¼Œå¯èƒ½æ˜¯ä½¿ç”¨æœ€å¹¿æ³›çš„ä¸€ç§ï¼‰ã€‚è¿˜æœ‰æ›´å¤šå…¶ä»–æ–¹å¼ï¼Œä½œä¸ºå®˜æ–¹æˆ–ç¬¬ 3 æ–¹æ’ä»¶å®ç°ï¼Œä½†å®ƒä»¬éƒ½ä¸¥é‡ä¾èµ– [Linux ç½‘ç»œè™šæ‹ŸåŒ–è®¾æ–½](https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/)ã€‚å› æ­¤ï¼Œå®¹å™¨åŒ–å¯ä»¥è¯´æ˜¯ä¸€ç§è™šæ‹ŸåŒ–æŠ€æœ¯ã€‚

Make code, not war!

ç¼–å†™ä»£ç ï¼Œè€Œä¸æ˜¯æˆ˜äº‰ï¼

### References:

###  å‚è€ƒï¼š

- [Introduction to Linux interfaces for virtual networking](https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/)
- [ip(8) â€” Linux manual page](https://man7.org/linux/man-pages/man8/ip.8.html)
- â­[Linux Bridge - Part 1](https://hechao.li/2017/12/13/linux-bridge-part1/) by [Hechao Li](https://hechao.li/aboutme/) (and more techical [Part 2](https://hechao.li/2018/01/31/linux-bridge-part2/))
- [Anatomy of a Linux bridge](https://wiki.aalto.fi/download/attachments/70789083/linux_bridging_final.pdf)
- [A container networking overview](https://jvns.ca/blog/2016/12/22/container-networking/)
- [Demystifying container networking](https://blog.mbrt.dev/2017-10-01-demystifying-container-networking/)
- [Introducing Linux Network Namespaces](https://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/)
- ğŸ¥[Container Networking From Scratch](https://www.youtube.com/watch?v=6v_BDHIgOY8&list=WL&index=2&t=0s)

- [Linux è™šæ‹Ÿç½‘ç»œæ¥å£ä»‹ç»](https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/)
- [ip(8) â€” Linux æ‰‹å†Œé¡µ](https://man7.org/linux/man-pages/man8/ip.8.html)
- â­[Linux Bridge - Part 1](https://hechao.li/2017/12/13/linux-bridge-part1/) by [Hechao Li](https://hechao.li/aboutme/)ï¼ˆå’Œæ›´å¤šæŠ€æœ¯[ç¬¬2éƒ¨åˆ†](https://hechao.li/2018/01/31/linux-bridge-part2/))
- [Linux ç½‘æ¡¥å‰–æ](https://wiki.aalto.fi/download/attachments/70789083/linux_bridging_final.pdf)
- [å®¹å™¨ç½‘ç»œæ¦‚è¿°](https://jvns.ca/blog/2016/12/22/container-networking/)
- [æ­ç§˜å®¹å™¨ç½‘ç»œ](https://blog.mbrt.dev/2017-10-01-demystifying-container-networking/)
- [Linux ç½‘ç»œå‘½åç©ºé—´ä»‹ç»](https://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/)
- ğŸ¥[ä»å¤´å¼€å§‹å®¹å™¨ç½‘ç»œ](https://www.youtube.com/watch?v=6v_BDHIgOY8&list=WL&index=2&t=0s)

### More [Networking](http://iximiuz.com/en/categories/?category=Networking) articles

### æ›´å¤š[ç½‘ç»œ](http://iximiuz.com/en/categories/?category=Networking) æ–‡ç« 

- [How to Expose Multiple Containers On the Same Port](http://iximiuz.com/en/posts/multiple-containers-same-port-reverse-proxy/)
- [Computer Networking Introduction - Ethernet and IP (Heavily Illustrated)](http://iximiuz.com/en/posts/computer-networking-101/) 

- [å¦‚ä½•åœ¨åŒä¸€ä¸ªç«¯å£ä¸Šæš´éœ²å¤šä¸ªå®¹å™¨](http://iximiuz.com/en/posts/multiple-containers-same-port-reverse-proxy/)
- [è®¡ç®—æœºç½‘ç»œä»‹ç» - ä»¥å¤ªç½‘å’Œ IPï¼ˆå¤§é‡æ’å›¾ï¼‰](http://iximiuz.com/en/posts/computer-networking-101/)

- [Bridge vs Switch: What I Learned From a Data Center Tour](http://iximiuz.com/en/posts/bridge-vs-switch/)
- [Illustrated introduction to Linux iptables](http://iximiuz.com/en/posts/laymans-iptables-101/)

- [Bridge vs Switchï¼šæˆ‘ä»æ•°æ®ä¸­å¿ƒä¹‹æ—…ä¸­å­¦åˆ°çš„ä¸œè¥¿](http://iximiuz.com/en/posts/bridge-vs-switch/)
-  [Linux iptables å›¾è§£ä»‹ç»](http://iximiuz.com/en/posts/laymans-iptables-101/)

### Other [Containers](http://iximiuz.com/en/categories/?category=Containers) articles

### å…¶ä»– [å®¹å™¨](http://iximiuz.com/en/categories/?category=Containers) æ–‡ç« 

- [Not every container has an operating system inside](http://iximiuz.com/en/posts/not-every-container-has-an-operating-system-inside/)
- [You don't need an image to run a container](http://iximiuz.com/en/posts/you-dont-need-an-image-to-run-a-container/)
- [You need containers to build images](http://iximiuz.com/en/posts/you-need-containers-to-build-an-image/)

- [å¹¶éæ¯ä¸ªå®¹å™¨å†…éƒ¨éƒ½æœ‰æ“ä½œç³»ç»Ÿ](http://iximiuz.com/en/posts/not-every-container-has-an-operating-system-inside/)
- [ä½ ä¸éœ€è¦å›¾åƒæ¥è¿è¡Œå®¹å™¨](http://iximiuz.com/en/posts/you-dont-need-an-image-to-run-a-container/)
- [ä½ éœ€è¦å®¹å™¨æ¥æ„å»ºé•œåƒ](http://iximiuz.com/en/posts/you-need-containers-to-build-an-image/)

[docker,](javascript: void 0) [linux,](javascript: void 0) [container](javascript: void 0)

[docker,](javascript: void 0) [linux,](javascript: void 0) [container](javascript: void 0)

#### Written by Ivan Velichko

#### ç”±ä¼Šä¸‡Â·ç»´åˆ©å¥‡ç§‘ (Ivan Velichko) æ’°å†™

_Follow me on twitter [@iximiuz](https://twitter.com/iximiuz)_

_åœ¨æ¨ç‰¹ä¸Šå…³æ³¨æˆ‘ [@iximiuz](https://twitter.com/iximiuz)_

Liked this article? Let it be the beginning of a great friendship. Leave your email so I could notify you about new articles or any other interesting happenings around the topics of this blog. No spam whatsoever, I promise!

å–œæ¬¢è¿™ç¯‡æ–‡ç« å—ï¼Ÿè®©å®ƒæˆä¸ºä¸€æ®µä¼Ÿå¤§å‹è°Šçš„å¼€å§‹ã€‚ç•™ä¸‹æ‚¨çš„ç”µå­é‚®ä»¶ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥é€šçŸ¥æ‚¨æœ‰å…³æ­¤åšå®¢ä¸»é¢˜çš„æ–°æ–‡ç« æˆ–ä»»ä½•å…¶ä»–æœ‰è¶£çš„äº‹ä»¶ã€‚æ²¡æœ‰ä»»ä½•åƒåœ¾é‚®ä»¶ï¼Œæˆ‘ä¿è¯ï¼

Copyright Ivan Velichko Â© 2021Â FeedÂ [Atom](http://iximiuz.com/feed.atom)[RSS](http://iximiuz.com/feed.rss) 

ç‰ˆæƒæ‰€æœ‰ Ivan Velichko Â© 2021 Feed [Atom](http://iximiuz.com/feed.atom)[RSS](http://iximiuz.com/feed.rss)

