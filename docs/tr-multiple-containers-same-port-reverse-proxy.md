# How to Expose Multiple Containers On the Same Port

# å¦‚ä½•åœ¨åŒä¸€ä¸ªç«¯å£ä¸Šæš´éœ²å¤šä¸ªå®¹å™¨

August 28, 2021

2021 å¹´ 8 æœˆ 28 æ—¥

[Containers,](http://iximiuz.com/en/categories/?category=Containers)[Networking,](http://iximiuz.com/en/categories/?category=Networking) [Linux / Unix]( http://iximiuz.com/en/categories/?category=Linux / Unix)

[å®¹å™¨ï¼Œ](http://iximiuz.com/en/categories/?category=Containers)[ç½‘ç»œï¼Œ](http://iximiuz.com/en/categories/?category=Networking) [Linux / Unix]( http://iximiuz.com/en/categories/?category=Linux / Unix)

_**Disclaimer:** In 2021, there is still a place for simple setups with just one machine serving all traffic. So, no Kubernetes and no cloud load balancers in this post. Just good old Docker and Podman._

_**å…è´£å£°æ˜ï¼š** åœ¨ 2021 å¹´ï¼Œä»ç„¶æœ‰ä¸€ä¸ªåœ°æ–¹å¯ä»¥è¿›è¡Œç®€å•çš„è®¾ç½®ï¼Œåªéœ€ä¸€å°æœºå™¨æœåŠ¡æ‰€æœ‰æµé‡ã€‚å› æ­¤ï¼Œæœ¬æ–‡ä¸­æ²¡æœ‰ Kubernetes å’Œäº‘è´Ÿè½½å‡è¡¡å™¨ã€‚å¥½è€çš„ Docker å’Œ Podmanã€‚_

Even when you have just one physical or virtual server, it's often a good idea to run multiple instances of your application on it. Luckily, when the application is containerized, it's actually relatively simple. With multiple application containers, you get **horizontal scaling** and a much-needed **redundancy** for a very little price. Thus, if there is a sudden need for handling more requests, you can adjust the number of containers accordingly. And if one of the containers dies, there are others to handle its traffic share, so your app isn't a [SPOF](https://en.wikipedia.org/wiki/Single_point_of_failure) anymore.

å³ä½¿æ‚¨åªæœ‰ä¸€å°ç‰©ç†æˆ–è™šæ‹ŸæœåŠ¡å™¨ï¼Œåœ¨å…¶ä¸Šè¿è¡Œåº”ç”¨ç¨‹åºçš„å¤šä¸ªå®ä¾‹é€šå¸¸ä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚å¹¸è¿çš„æ˜¯ï¼Œå½“åº”ç”¨ç¨‹åºè¢«å®¹å™¨åŒ–æ—¶ï¼Œå®ƒå®é™…ä¸Šç›¸å¯¹ç®€å•ã€‚å€ŸåŠ©å¤šä¸ªåº”ç”¨ç¨‹åºå®¹å™¨ï¼Œæ‚¨å¯ä»¥ä»¥æä½çš„ä»·æ ¼è·å¾—**æ°´å¹³æ‰©å±•** å’Œæ€¥éœ€çš„**å†—ä½™**ã€‚å› æ­¤ï¼Œå¦‚æœçªç„¶éœ€è¦å¤„ç†æ›´å¤šè¯·æ±‚ï¼Œæ‚¨å¯ä»¥ç›¸åº”åœ°è°ƒæ•´å®¹å™¨æ•°é‡ã€‚å¦‚æœå…¶ä¸­ä¸€ä¸ªå®¹å™¨æ­»äº¡ï¼Œè¿˜æœ‰å…¶ä»–å®¹å™¨æ¥å¤„ç†å…¶æµé‡ä»½é¢ï¼Œå› æ­¤æ‚¨çš„åº”ç”¨ä¸å†æ˜¯ [SPOF](https://en.wikipedia.org/wiki/Single_point_of_failure)ã€‚

The tricky part here is how to expose such a multi-container application to the clients. Multiple containers mean multiple listening sockets. But most of the time, clients just want to have a single point of entry.

è¿™é‡Œçš„æ£˜æ‰‹éƒ¨åˆ†æ˜¯å¦‚ä½•å‘å®¢æˆ·ç«¯å…¬å¼€è¿™æ ·ä¸€ä¸ªå¤šå®¹å™¨åº”ç”¨ç¨‹åºã€‚å¤šä¸ªå®¹å™¨æ„å‘³ç€å¤šä¸ªä¾¦å¬å¥—æ¥å­—ã€‚ä½†å¤§å¤šæ•°æ—¶å€™ï¼Œå®¢æˆ·åªæƒ³æœ‰ä¸€ä¸ªå•ä¸€çš„å…¥å£ç‚¹ã€‚

![Benefits of exposing multiple Docker containers on the same port](http://iximiuz.com/multiple-containers-same-port-reverse-proxy/multiple-containers-same-port-2000-opt.png)

Surprisingly or not, neither Docker nor Podman [support exposing multiple containers on the same host's port](https://github.com/docker/for-linux/issues/471) right out of the box.

ä¸ç®¡æ˜¯å¦ä»¤äººæƒŠè®¶ï¼ŒDocker å’Œ Podman [æ”¯æŒåœ¨åŒä¸€ä¸»æœºçš„ç«¯å£ä¸Šå…¬å¼€å¤šä¸ªå®¹å™¨](https://github.com/docker/for-linux/issues/471) éƒ½ä¸æ˜¯å¼€ç®±å³ç”¨çš„ã€‚

Example: `docker-compose` failing scenario with `"Service specifies a port on the host. If multiple containers for this service are created on a single host, the port will clash."`

ç¤ºä¾‹ï¼š`docker-compose` å¤±è´¥åœºæ™¯ï¼Œå¸¦æœ‰ `"Service åœ¨ä¸»æœºä¸ŠæŒ‡å®šä¸€ä¸ªç«¯å£ã€‚å¦‚æœåœ¨å•ä¸ªä¸»æœºä¸Šä¸ºè¯¥æœåŠ¡åˆ›å»ºå¤šä¸ªå®¹å™¨ï¼Œç«¯å£å°†å‘ç”Ÿå†²çªã€‚"`

For instance, if you have the following docker-compose file:

ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰ä»¥ä¸‹ docker-compose æ–‡ä»¶ï¼š

```yaml
version: '3'
services:
app:
    image: kennethreitz/httpbin
    ports:
      - "80:80"  # httpbin server listens on the container's 0.0.0.0:80

```

And you want to scale up the `app` service with `docker-compose up --scale app=2`, you'll get the following error:

å¦‚æœä½ æƒ³ç”¨ `docker-compose up --scale app=2` æ¥æ‰©å±• `app` æœåŠ¡ï¼Œä½ ä¼šå¾—åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

```bash
WARNING: The "app" service specifies a port on the host.If multiple containers for this service are created on a single host, the port will clash.
Starting example_app_1 ... done
Creating example_app_2 ...
Creating example_app_2 ... error

ERROR: for example_app_2  Cannot start service app: driver failed programming external connectivity on endpoint example_app_2 (...): Bind for 0.0.0.0:80 failed: port is already allocated

ERROR: for app  Cannot start service app: driver failed programming external connectivity on endpoint example_app_2 (...): Bind for 0.0.0.0:80 failed: port is already allocated
ERROR: Encountered errors while bringing up the project.

```

The most widely suggested workaround is to use an extra container with a reverse proxy like Nginx, HAProxy, Envoy, or Traefik. Such a proxy should know the exact set of application containers and load balance the client traffic between them. The only port that needs to be exposed on the host in such a setup is the port of the proxy itself. Additionally, since modern reverse proxies usually come with advanced routing capabilities, you can get **canary and blue-green deployments** or even coalesce **diverse backend apps into a single fronted app** almost for free.

æœ€å¹¿æ³›å»ºè®®çš„è§£å†³æ–¹æ³•æ˜¯ä½¿ç”¨å¸¦æœ‰åå‘ä»£ç†çš„é¢å¤–å®¹å™¨ï¼Œä¾‹å¦‚ Nginxã€HAProxyã€Envoy æˆ– Traefikã€‚è¿™æ ·çš„ä»£ç†åº”è¯¥çŸ¥é“åº”ç”¨ç¨‹åºå®¹å™¨çš„ç¡®åˆ‡é›†åˆå¹¶è´Ÿè½½å¹³è¡¡å®ƒä»¬ä¹‹é—´çš„å®¢æˆ·ç«¯æµé‡ã€‚åœ¨è¿™ç§è®¾ç½®ä¸­ï¼Œå”¯ä¸€éœ€è¦åœ¨ä¸»æœºä¸Šå…¬å¼€çš„ç«¯å£æ˜¯ä»£ç†æœ¬èº«çš„ç«¯å£ã€‚æ­¤å¤–ï¼Œç”±äºç°ä»£åå‘ä»£ç†é€šå¸¸å…·æœ‰é«˜çº§è·¯ç”±åŠŸèƒ½ï¼Œæ‚¨å‡ ä¹å¯ä»¥å…è´¹è·å¾—**é‡‘ä¸é›€å’Œè“ç»¿éƒ¨ç½²**ï¼Œç”šè‡³å¯ä»¥å°†**ä¸åŒçš„åç«¯åº”ç”¨ç¨‹åºåˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€çš„å‰ç«¯åº”ç”¨ç¨‹åº**ã€‚

For any production setup, [I'd recommend going with a reverse proxy approach first](http://iximiuz.com#reverse-proxy). But in this post, I want to explore the alternatives. Are there other ways to expose multiple Docker or Podman containers on the same host's port? 

å¯¹äºä»»ä½•ç”Ÿäº§è®¾ç½®ï¼Œ[æˆ‘å»ºè®®é¦–å…ˆä½¿ç”¨åå‘ä»£ç†æ–¹æ³•](http://iximiuz.com#reverse-proxy)ã€‚ä½†åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æƒ³æ¢ç´¢æ›¿ä»£æ–¹æ¡ˆã€‚è¿˜æœ‰å…¶ä»–æ–¹æ³•å¯ä»¥åœ¨åŒä¸€ä¸»æœºçš„ç«¯å£ä¸Šå…¬å¼€å¤šä¸ª Docker æˆ– Podman å®¹å™¨å—ï¼Ÿ

The goal of the below exercise is manifold. First of all, to solidify the knowledge obtained while working on my [container networking](http://iximiuz.com/en/posts/container-networking-is-simple/) and [iptables](http://iximiuz.com/en/posts/laymans-iptables-101/) write-ups. But also to show that the proxy is not the only possible way to achieve a decent load balancing. So, if you are in a restricted setup where you can't use a proxy for some reason, the techniques from this post may come in handy.

ä»¥ä¸‹ç»ƒä¹ çš„ç›®æ ‡æ˜¯å¤šæ–¹é¢çš„ã€‚é¦–å…ˆï¼Œå·©å›ºåœ¨æˆ‘çš„[å®¹å™¨ç½‘ç»œ](http://iximiuz.com/en/posts/container-networking-is-simple/)å’Œ[iptables](http://iximiuz.com/en/posts/laymans-iptables-101/) æ–‡ç« ã€‚ä½†ä¹Ÿè¡¨æ˜ä»£ç†ä¸æ˜¯å®ç°ä½“é¢è´Ÿè½½å¹³è¡¡çš„å”¯ä¸€å¯èƒ½æ–¹æ³•ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨å¤„äºç”±äºæŸç§åŸå› æ— æ³•ä½¿ç”¨ä»£ç†çš„å—é™è®¾ç½®ä¸­ï¼Œé‚£ä¹ˆæœ¬æ–‡ä¸­çš„æŠ€æœ¯å¯èƒ½ä¼šæ´¾ä¸Šç”¨åœºã€‚

## Multiple Containers / Same Port using SO\_REUSEPORT

## ä½¿ç”¨ SO\_REUSEPORT çš„å¤šä¸ªå®¹å™¨/åŒä¸€ç«¯å£

Let's forget about containers for a second and talk about sockets in general.

è®©æˆ‘ä»¬æš‚æ—¶å¿˜æ‰å®¹å™¨ï¼Œæ¥è°ˆè°ˆä¸€èˆ¬çš„å¥—æ¥å­—ã€‚

To make a server socket [`listen()`](https://man7.org/linux/man-pages/man2/listen.2.html) on a certain address, you need to explicitly [`bind()` ](https://man7.org/linux/man-pages/man2/bind.2.html) it to an interface and port. For a long time, binding a socket to an _(interface, port)_ pair was an exclusive operation. If you bound a socket to a certain address from one process, no other processes on the same machine would be able to use the same address for their sockets until the original process closes its socket (hence, releases the port). And it's kind of reasonable behavior - an interface and port define a packet destination on a machine. Having ambiguous receivers would be bizarre.

è¦åœ¨æŸä¸ªåœ°å€ä¸Šåˆ›å»ºæœåŠ¡å™¨å¥—æ¥å­— [`listen()`](https://man7.org/linux/man-pages/man2/listen.2.html)ï¼Œéœ€è¦æ˜¾å¼[`bind()` ](https://man7.org/linux/man-pages/man2/bind.2.html) åˆ°ä¸€ä¸ªæ¥å£å’Œç«¯å£ã€‚é•¿æœŸä»¥æ¥ï¼Œå°†å¥—æ¥å­—ç»‘å®šåˆ° _(interface, port)_ å¯¹æ˜¯ä¸€ç§ç‹¬å æ“ä½œã€‚å¦‚æœæ‚¨å°†ä¸€ä¸ªå¥—æ¥å­—ç»‘å®šåˆ°ä¸€ä¸ªè¿›ç¨‹çš„æŸä¸ªåœ°å€ï¼Œé‚£ä¹ˆåœ¨åŸå§‹è¿›ç¨‹å…³é—­å…¶å¥—æ¥å­—ï¼ˆå› æ­¤é‡Šæ”¾ç«¯å£)ä¹‹å‰ï¼ŒåŒä¸€å°æœºå™¨ä¸Šçš„ä»»ä½•å…¶ä»–è¿›ç¨‹éƒ½æ— æ³•å¯¹å…¶å¥—æ¥å­—ä½¿ç”¨ç›¸åŒçš„åœ°å€ã€‚è¿™æ˜¯ä¸€ç§åˆç†çš„è¡Œä¸º - æ¥å£å’Œç«¯å£å®šä¹‰äº†æœºå™¨ä¸Šçš„æ•°æ®åŒ…ç›®çš„åœ°ã€‚æœ‰æ¨¡æ£±ä¸¤å¯çš„æ¥æ”¶è€…ä¼šå¾ˆå¥‡æ€ªã€‚

But... modern servers may need to handle tens of thousands of TCP connections per second. A single process [`accept()`](https://man7.org/linux/man-pages/man2/accept.2.html)-ing all the client connections quickly becomes a bottleneck with such a high connection rate. So, starting from Linux 3.9, [you can bind an arbitrary number of sockets to exactly the same _(interface, port)_ pair](https://lwn.net/Articles/542629/) as long as all of them use the `SO_REUSEPORT` socket option. The operating system then will make sure that TCP connections are evenly distributed between all the listening processes (or threads).

ä½†æ˜¯â€¦â€¦ç°ä»£æœåŠ¡å™¨æ¯ç§’å¯èƒ½éœ€è¦å¤„ç†æ•°ä¸‡ä¸ª TCP è¿æ¥ã€‚å•ä¸ªè¿›ç¨‹ [`accept()`](https://man7.org/linux/man-pages/man2/accept.2.html)-æ‰€æœ‰å®¢æˆ·ç«¯è¿æ¥å¾ˆå¿«æˆä¸ºå…·æœ‰å¦‚æ­¤é«˜è¿æ¥é€Ÿç‡çš„ç“¶é¢ˆã€‚æ‰€ä»¥ï¼Œä» Linux 3.9 å¼€å§‹ï¼Œ[ä½ å¯ä»¥å°†ä»»æ„æ•°é‡çš„å¥—æ¥å­—ç»‘å®šåˆ°å®Œå…¨ç›¸åŒçš„ _(interface, port)_ å¯¹](https://lwn.net/Articles/542629/) åªè¦å®ƒä»¬éƒ½ä½¿ç”¨`SO_REUSEPORT` å¥—æ¥å­—é€‰é¡¹ã€‚ç„¶åæ“ä½œç³»ç»Ÿå°†ç¡®ä¿ TCP è¿æ¥åœ¨æ‰€æœ‰ä¾¦å¬è¿›ç¨‹ï¼ˆæˆ–çº¿ç¨‹)ä¹‹é—´å‡åŒ€åˆ†å¸ƒã€‚

Apparently, the same technique can be applied to containers. However, the `SO_REUSEPORT` option works only if all the sockets reside in the same network stack. And that's obviously not the case for the default Docker/Podman approach, where every container gets its own network namespace, hence an isolated network stack.

æ˜¾ç„¶ï¼ŒåŒæ ·çš„æŠ€æœ¯å¯ä»¥åº”ç”¨äºå®¹å™¨ã€‚ç„¶è€Œï¼Œ`SO_REUSEPORT` é€‰é¡¹åªæœ‰åœ¨æ‰€æœ‰å¥—æ¥å­—éƒ½é©»ç•™åœ¨åŒä¸€ä¸ªç½‘ç»œå †æ ˆä¸­æ—¶æ‰æœ‰æ•ˆã€‚è€Œé»˜è®¤çš„ Docker/Podman æ–¹æ³•æ˜¾ç„¶ä¸æ˜¯è¿™ç§æƒ…å†µï¼Œæ¯ä¸ªå®¹å™¨éƒ½æœ‰è‡ªå·±çš„ç½‘ç»œå‘½åç©ºé—´ï¼Œå› æ­¤æ˜¯ä¸€ä¸ªéš”ç¦»çš„ç½‘ç»œå †æ ˆã€‚

The simplest way to overcome this is to sacrifice the isolation a bit and run all the containers in the host's network namespace with `docker run --network host`:

å…‹æœè¿™ä¸ªé—®é¢˜çš„æœ€ç®€å•æ–¹æ³•æ˜¯ç‰ºç‰²ä¸€ç‚¹éš”ç¦»æ€§ï¼Œå¹¶ä½¿ç”¨ `docker run --network host` è¿è¡Œä¸»æœºç½‘ç»œå‘½åç©ºé—´ä¸­çš„æ‰€æœ‰å®¹å™¨ï¼š

![Multiple Docker containers listening on the same port with SO_REUSEPORT](http://iximiuz.com/multiple-containers-same-port-reverse-proxy/multiple-containers-same-port-so_reuseport-2000-opt.png)

But there is a more subtle way to share a single network namespace between multiple containers. Docker allows reusing a network namespace of an already existing container while launching a new one. So, we can start a _sandbox_ container that will do nothing but sleep. This container will originate a network namespace and also expose the target port to the host (other namespaces will also be created, but it doesn't really matter). All the application containers will then be attached to this network namespace using `docker run --network container:<sandbox_name>` syntax.

ä½†æ˜¯æœ‰ä¸€ç§æ›´å¾®å¦™çš„æ–¹æ³•å¯ä»¥åœ¨å¤šä¸ªå®¹å™¨ä¹‹é—´å…±äº«å•ä¸ªç½‘ç»œå‘½åç©ºé—´ã€‚ Docker å…è®¸åœ¨å¯åŠ¨æ–°å®¹å™¨æ—¶é‡ç”¨ç°æœ‰å®¹å™¨çš„ç½‘ç»œå‘½åç©ºé—´ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥å¯åŠ¨ä¸€ä¸ª _sandbox_ å®¹å™¨ï¼Œå®ƒé™¤äº†ç¡çœ ä¹‹å¤–ä»€ä¹ˆéƒ½ä¸åšã€‚è¿™ä¸ªå®¹å™¨å°†åˆ›å»ºä¸€ä¸ªç½‘ç»œå‘½åç©ºé—´ï¼Œå¹¶å°†ç›®æ ‡ç«¯å£æš´éœ²ç»™ä¸»æœºï¼ˆä¹Ÿä¼šåˆ›å»ºå…¶ä»–å‘½åç©ºé—´ï¼Œä½†è¿™å¹¶ä¸é‡è¦ï¼‰ã€‚ç„¶åï¼Œæ‰€æœ‰åº”ç”¨ç¨‹åºå®¹å™¨éƒ½å°†ä½¿ç”¨ `docker run --network container:<sandbox_name>` è¯­æ³•é™„åŠ åˆ°è¿™ä¸ªç½‘ç»œå‘½åç©ºé—´ã€‚

_**NB:** We just reinvented Kubernetes pods here - check out the [Kubernetes CRI](https://github.com/kubernetes/cri-api/blob/d059f89d4bb00d7f29a89808f43e063ce35b50de/pkg/apis/services.go#L63-L79) spec._

_**æ³¨æ„ï¼š** æˆ‘ä»¬åˆšåˆšåœ¨è¿™é‡Œé‡æ–°å‘æ˜äº† Kubernetes pod - æŸ¥çœ‹ [Kubernetes CRI](https://github.com/kubernetes/cri-api/blob/d059f89d4bb00d7f29a89808f43e063ce35b50de/pkg/apis/services.go#L63-L79) è§„æ ¼_

![Multiple Docker containers listening on the same port with SO_REUSEPORT and sandbox container network namespace](http://iximiuz.com/multiple-containers-same-port-reverse-proxy/multiple-containers-same-port-so_reuseport-netns-2000-opt.png)

-2000-opt.png)

Of course, all the instances of the application server need to set the `SO_REUSEPORT` option, so there won't be a port conflict, and the incoming requests will be evenly distributed between the containers listening on the same port.

å½“ç„¶ï¼Œåº”ç”¨æœåŠ¡å™¨çš„æ‰€æœ‰å®ä¾‹éƒ½éœ€è¦è®¾ç½®`SO_REUSEPORT`é€‰é¡¹ï¼Œè¿™æ ·å°±ä¸ä¼šæœ‰ç«¯å£å†²çªï¼Œä¼ å…¥çš„è¯·æ±‚ä¼šåœ¨ç›‘å¬åŒä¸€ä¸ªç«¯å£çš„å®¹å™¨ä¹‹é—´å‡åŒ€åˆ†å¸ƒã€‚

Example Go server using `SO_REUSEPORT` socket option.

ç¤ºä¾‹ Go æœåŠ¡å™¨ä½¿ç”¨ SO_REUSEPORT å¥—æ¥å­—é€‰é¡¹ã€‚

Here is an example Go server that uses the `SO_REUSEPORT` option. [Setting socket options in Go](http://iximiuz.com/en/posts/go-net-http-setsockopt-example/) turned out to be slightly less trivial than I expected ğŸ™ˆ

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ SO_REUSEPORT é€‰é¡¹çš„ Go æœåŠ¡å™¨ç¤ºä¾‹ã€‚ [åœ¨ Go ä¸­è®¾ç½®å¥—æ¥å­—é€‰é¡¹](http://iximiuz.com/en/posts/go-net-http-setsockopt-example/) ç»“æœæ¯”æˆ‘é¢„æœŸçš„è¦ç®€å•ä¸€äº›ğŸ™ˆ

```go
// http_server.go

package main

import (
    "context"
    "fmt"
    "net"
    "net/http"
    "os"
    "syscall"

    "golang.org/x/sys/unix"
)

func main() {
    lc := net.ListenConfig{
        Control: func(network, address string, conn syscall.RawConn) error {
            var operr error
            if err := conn.Control(func(fd uintptr) {
                operr = syscall.SetsockoptInt(
                    int(fd),
                    unix.SOL_SOCKET,
                    unix.SO_REUSEPORT,
                    1,
                )
            });err != nil {
                return err
            }
            return operr
        },
    }

    ln, err := lc.Listen(
        context.Background(),
        "tcp",
        os.Getenv("HOST")+":"+os.Getenv("PORT"),
    )
    if err != nil {
        panic(err)
    }

    http.HandleFunc("/", func(w http.ResponseWriter, _req *http.Request) {
        w.Write([]byte(fmt.Sprintf("Hello from %s\n", os.Getenv("INSTANCE"))))
    })

    if err := http.Serve(ln, nil);err != nil {
        panic(err)
    }
}

```

Use the following _Dockerfile_ (not for production!) to containerize the above server:

ä½¿ç”¨ä»¥ä¸‹ _Dockerfile_ï¼ˆä¸é€‚ç”¨äºç”Ÿäº§ï¼ï¼‰æ¥å®¹å™¨åŒ–ä¸Šè¿°æœåŠ¡å™¨ï¼š

```dockerfile
FROM golang:1.16

COPY http_server.go .

ENV GO111MODULE=off

RUN go get golang.org/x/sys/unix

CMD ["go", "run", "http_server.go"]

```

Build it with `docker build -t http_server .`

ä½¿ç”¨`docker build -t http_server æ„å»ºå®ƒã€‚

Here is a step by step instruction on how to launch the sandbox and the application containers:

ä»¥ä¸‹æ˜¯æœ‰å…³å¦‚ä½•å¯åŠ¨æ²™ç®±å’Œåº”ç”¨ç¨‹åºå®¹å™¨çš„åˆ†æ­¥è¯´æ˜ï¼š

```bash
# Prepare the sandbox.
$ docker run -d --rm \
  --name app_sandbox \
  -p 80:8080 \
alpine sleep infinity

# Run first application container.
$ docker run -d --rm \
  --network container:app_sandbox \
  -e INSTANCE=foo \
  -e HOST=0.0.0.0 \
  -e PORT=8080 \
http_server

# Run second application container.
$ docker run -d --rm \
  --network container:app_sandbox \
  -e INSTANCE=bar \
  -e HOST=0.0.0.0 \
  -e PORT=8080 \
http_server

```

Testing it on a vagrant box with `curl` gave me the following results:

åœ¨å¸¦æœ‰ `curl` çš„æµæµªç›’å­ä¸Šæµ‹è¯•å®ƒç»™äº†æˆ‘ä»¥ä¸‹ç»“æœï¼š

```bash
# 192.168.37.99 is the external interface of the VM.

$ for i in {1..300};do curl -s 192.168.37.99 2>&1;done |sort |uniq -c
158 Hello from bar
142 Hello from foo

```

Pretty good distribution, huh?

å¾ˆå¥½çš„åˆ†å¸ƒï¼Œå¯¹å§ï¼Ÿ

## Multiple Containers / Same Port using DNAT

## ä½¿ç”¨ DNAT çš„å¤šä¸ªå®¹å™¨/åŒä¸€ç«¯å£

To understand the technique from this section, you need to know what happens when a container's port is published on the host. At first sight, it may look like there is indeed a process listening on the host and forwarding packets to the container (scroll to the right end):

è¦ç†è§£æœ¬èŠ‚ä¸­çš„æŠ€æœ¯ï¼Œæ‚¨éœ€è¦çŸ¥é“åœ¨ä¸»æœºä¸Šå‘å¸ƒå®¹å™¨çš„ç«¯å£æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚ä¹ä¸€çœ‹ï¼Œçœ‹èµ·æ¥ç¡®å®æœ‰ä¸€ä¸ªè¿›ç¨‹åœ¨ç›‘å¬ä¸»æœºå¹¶å°†æ•°æ®åŒ…è½¬å‘åˆ°å®¹å™¨ï¼ˆæ»šåŠ¨åˆ°å³ç«¯ï¼‰ï¼š

```bash
# Start a container with port 8080 published on host's port 80.
$ docker run -d --rm -p 80:8080 alpine sleep infinity

# Check listening TCP sockets.
$ sudo ss -lptn 'sport = :80'
State   Recv-Q  Send-Q  Local Address:Port  Peer Address:Port
LISTEN  0       128           0.0.0.0:80          0.0.0.0:*    users:(("docker-proxy",pid=4963,fd=4))
LISTEN  0       128              [::]:80             [::]:*    users:(("docker-proxy",pid=4970,fd=4))

```

[In actuality, the userland `docker-proxy` is rarely used.](https://windsock.io/the-docker-proxy/) Instead, a single iptables rule in the NAT table does all the heavy lifting. Whenever a packet destined to the _(host, published\_port)_ arrives, a destination address translation to _(container, target\_port)_ happens. So, the [port publishing boils down to adding this iptables rule upon the container startup](http://iximiuz.com/en/posts/container-networking-is-simple/#port-publishing).

[å®é™…ä¸Šï¼Œç”¨æˆ·ç©ºé—´ `docker-proxy` å¾ˆå°‘ä½¿ç”¨ã€‚](https://windsock.io/the-docker-proxy/) ç›¸åï¼ŒNAT è¡¨ä¸­çš„å•ä¸ª iptables è§„åˆ™å®Œæˆäº†æ‰€æœ‰ç¹é‡çš„å·¥ä½œã€‚æ¯å½“å‘å¾€ _(host,published\_port)_ çš„æ•°æ®åŒ…åˆ°è¾¾æ—¶ï¼Œå°±ä¼šå‘ç”Ÿåˆ° _(container, target\_port)_ çš„ç›®çš„åœ°åœ°å€è½¬æ¢ã€‚å› æ­¤ï¼Œ[ç«¯å£å‘å¸ƒå½’ç»“ä¸ºåœ¨å®¹å™¨å¯åŠ¨æ—¶æ·»åŠ æ­¤ iptables è§„åˆ™](http://iximiuz.com/en/posts/container-networking-is-simple/#port-publishing)ã€‚

_**NB:** The iptables trick doesn't cover all the scenarios - for instance, traffic from `localhost` cannot be NAT-ed. So the `docker-proxy` is not fully useless_.

_**æ³¨æ„ï¼š** iptables æŠ€å·§å¹¶æ²¡æœ‰æ¶µç›–æ‰€æœ‰åœºæ™¯â€”â€”ä¾‹å¦‚ï¼Œæ¥è‡ª`localhost` çš„æµé‡ä¸èƒ½è¢« NAT-edã€‚æ‰€ä»¥`docker-proxy` å¹¶ä¸æ˜¯å®Œå…¨æ²¡ç”¨çš„_ã€‚

![Docker publishes container port on the host.](http://iximiuz.com/multiple-containers-same-port-reverse-proxy/docker-proxy-2000-opt.png)

The problem with the above DNAT is that it can do only the one-to-one translation. Thus, if we want to support multiple containers behind a single host's port, we need a more sophisticated solution. Luckily, [Kubernetes uses a similar trick in `kube-proxy` for the _Service ClusterIP to Pod IPs_ translation](https://arthurchiao.art/blog/cracking-k8s-node-proxy/) while implementing a [built-in service discovery](http://iximiuz.com/en/posts/service-discovery-in-kubernetes/).

ä¸Šè¿°DNATçš„é—®é¢˜åœ¨äºå®ƒåªèƒ½è¿›è¡Œä¸€å¯¹ä¸€çš„ç¿»è¯‘ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³åœ¨å•ä¸ªä¸»æœºçš„ç«¯å£åé¢æ”¯æŒå¤šä¸ªå®¹å™¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ›´å¤æ‚çš„è§£å†³æ–¹æ¡ˆã€‚å¹¸è¿çš„æ˜¯ï¼Œ[Kubernetes åœ¨`kube-proxy` ä¸­ä½¿ç”¨äº†ç±»ä¼¼çš„æŠ€å·§æ¥å®ç° _Service ClusterIP åˆ° Pod IPs_ çš„è½¬æ¢](https://arthurchio.art/blog/cracking-k8s-node-proxy/) åŒæ—¶å®ç°äº†ä¸€ä¸ª [å†…ç½®æœåŠ¡å‘ç°](http://iximiuz.com/en/posts/service-discovery-in-kubernetes/)ã€‚

Long story short, iptables rules can be applied with some probability. So, if you have ten potential destinations for a packet, try applying the destination address translation to the first nine one of them with just a 10% chance. And if none of them worked out, apply a fallback for the very last destination with a 100% chance. As a result, you'll get ten equally loaded destinations.

é•¿è¯çŸ­è¯´ï¼Œiptables è§„åˆ™å¯ä»¥ä»¥ä¸€å®šçš„æ¦‚ç‡åº”ç”¨ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨æœ‰ 10 ä¸ªæ•°æ®åŒ…çš„æ½œåœ¨ç›®çš„åœ°ï¼Œè¯·å°è¯•å°†ç›®çš„åœ°åœ°å€è½¬æ¢åº”ç”¨äºå…¶ä¸­çš„å‰ä¹ä¸ªï¼Œåªæœ‰ 10% çš„æœºä¼šã€‚å¦‚æœå®ƒä»¬éƒ½æ²¡æœ‰è§£å†³ï¼Œåˆ™ä»¥ 100% çš„æœºä¼šå¯¹æœ€åä¸€ä¸ªç›®çš„åœ°åº”ç”¨åå¤‡ã€‚å› æ­¤ï¼Œæ‚¨å°†è·å¾— 10 ä¸ªåŒç­‰è´Ÿè½½çš„ç›®çš„åœ°ã€‚

_**NB:** Of course, iptables are smart enough to apply the DNAT only to the new connections. For an already established connection, an existing address mapping is looked up on the fly._

_**æ³¨æ„ï¼š** å½“ç„¶ï¼Œiptables è¶³å¤Ÿèªæ˜ï¼Œå¯ä»¥å°† DNAT ä»…åº”ç”¨äºæ–°è¿æ¥ã€‚å¯¹äºå·²å»ºç«‹çš„è¿æ¥ï¼Œä¼šå³æ—¶æŸ¥æ‰¾ç°æœ‰åœ°å€æ˜ å°„ã€‚_

![Multiple Docker containers exposed on the same port with iptables NAT rules](http://iximiuz.com/multiple-containers-same-port-reverse-proxy/multiple-containers-same-port-iptables-2000-opt.png)

png)

The huge advantage of this approach comparing to the `SO_REUSEPORT` option is that it's absolutely transparent to the application.

ä¸`SO_REUSEPORT` é€‰é¡¹ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•çš„å·¨å¤§ä¼˜åŠ¿åœ¨äºå®ƒå¯¹åº”ç”¨ç¨‹åºç»å¯¹é€æ˜ã€‚

Here is how you can quickly try it out.

ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å¿«é€Ÿè¯•ç”¨çš„æ–¹æ³•ã€‚

Example Go server.

ç¤ºä¾‹ Go æœåŠ¡å™¨ã€‚

We can use a much simpler version of the test server:

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´ç®€å•çš„æµ‹è¯•æœåŠ¡å™¨ç‰ˆæœ¬ï¼š

```go
// http_server.go
package main

import (
    "fmt"
    "net/http"
    "os"
)

func main() {
    http.HandleFunc("/", func(w http.ResponseWriter, _req *http.Request) {
        w.Write([]byte(fmt.Sprintf("Hello from %s\n", os.Getenv("INSTANCE"))))
    })

    if err := http.ListenAndServe(":"+os.Getenv("PORT"), nil);err != nil {
        panic(err)
    }
}

```

And the simplified _Dockerfile_:

ä»¥åŠç®€åŒ–çš„ _Dockerfile_ï¼š

```dockerfile
FROM golang:1.16

COPY http_server.go .

CMD ["go", "run", "http_server.go"]

```

Build it with:

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ„å»ºå®ƒï¼š

```bash
$ docker build -t http_server .

```

Run two application containers:

è¿è¡Œä¸¤ä¸ªåº”ç”¨ç¨‹åºå®¹å™¨ï¼š

```bash
$ CONT_PORT=9090

$ docker run -d --rm \
  --name http_server_foo \
  -e INSTANCE=foo \
  -e PORT=$CONT_PORT \
http_server

$ docker run -d --rm \
  --name http_server_bar \
  -e INSTANCE=bar \
  -e PORT=$CONT_PORT \
http_server

```

Figure out the IP addresses of the containers:

æ‰¾å‡ºå®¹å™¨çš„IPåœ°å€ï¼š

```bash
$ CONT_FOO_IP=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' http_server_foo)
$ echo $CONT_FOO_IP
172.17.0.2

$ CONT_BAR_IP=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' http_server_bar)
$ echo $CONT_BAR_IP
172.17.0.3

```

Configure iptables DNAT rules - for local ( `OUTPUT`) and external ( `PREROUTING`) traffic:

é…ç½® iptables DNAT è§„åˆ™ - ç”¨äºæœ¬åœ°ï¼ˆ`OUTPUT`ï¼‰å’Œå¤–éƒ¨ï¼ˆ`PREROUTING`ï¼‰æµé‡ï¼š

```bash
$ FRONT_PORT=80

# Not secure!Use global ACCEPT only for tests.
$ sudo iptables -I FORWARD 1 -j ACCEPT

# DNAT - local traffic
$ sudo iptables -t nat -I OUTPUT 1 -p tcp --dport $FRONT_PORT \
    -m statistic --mode random --probability 1.0  \
    -j DNAT --to-destination $CONT_FOO_IP:$CONT_PORT

$ sudo iptables -t nat -I OUTPUT 1 -p tcp --dport $FRONT_PORT \
    -m statistic --mode random --probability 0.5  \
    -j DNAT --to-destination $CONT_BAR_IP:$CONT_PORT

# DNAT - external traffic
$ sudo iptables -t nat -I PREROUTING 1 -p tcp --dport $FRONT_PORT \
    -m statistic --mode random --probability 1.0  \
    -j DNAT --to-destination $CONT_FOO_IP:$CONT_PORT

$ sudo iptables -t nat -I PREROUTING 1 -p tcp --dport $FRONT_PORT \
    -m statistic --mode random --probability 0.5  \
    -j DNAT --to-destination $CONT_BAR_IP:$CONT_PORT

```

Testing it on a vagrant box game with `curl` gave me the following request distribution:

ä½¿ç”¨ `curl` åœ¨ä¸€ä¸ªæµæµªç›’æ¸¸æˆä¸Šæµ‹è¯•å®ƒç»™äº†æˆ‘ä»¥ä¸‹è¯·æ±‚åˆ†å¸ƒï¼š

```bash
$ for i in {1..300};do curl -s 192.168.37.99 2>&1;done |sort |uniq -c
143 Hello from bar
157 Hello from foo

```

DON'T FORGET to clean up the iptables rules.

ä¸è¦å¿˜è®°æ¸…ç† iptables è§„åˆ™ã€‚

```bash
# Clean up filter rule (traffic forwarding)
$ sudo iptables -t filter -L -n --line-numbers

# Make sure your rule is on the first line, and then drop it
$ sudo iptables -t filter -D FORWARD 1

# Clean up nat rules (destination address replacement)
sudo iptables -t nat -L -n --line-numbers

# Make sure your rules are the first ones in the chains, and then drop them:
sudo iptables -t nat -D OUTPUT 1
sudo iptables -t nat -D OUTPUT 1
sudo iptables -t nat -D PREROUTING 1
sudo iptables -t nat -D PREROUTING 1

```

## Multiple Containers / Same Port using Reverse Proxy

## ä½¿ç”¨åå‘ä»£ç†çš„å¤šä¸ªå®¹å™¨/åŒä¸€ç«¯å£

When it comes to proxies, the most challenging part is how to deal with volatile sets of upstreams. Containers come and go, and their IP addresses are ephemeral. So, whenever a list of application containers changes, the proxy needs to update its list of upstream IPs. Docker has a built-in DNS server that maintains the up-to-date DNS records for the containers. However, [Nginx doesn't refresh the DNS resolution results unless some magic with variables is applied](https://www.ameyalokare.com/docker/2017/09/27/nginx-dynamic-upstreams-docker.html). Configuring [Envoy proxy with a STRICT\_DNS cluster may show better results](https://www.redhat.com/en/blog/configuring-envoy-auto-discover-pods-kubernetes). However, the best results can be achieved only by [dynamically updating the proxy configuration on the fly listening to Docker events](http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/).

è¯´åˆ°ä»£ç†ï¼Œæœ€å…·æŒ‘æˆ˜æ€§çš„éƒ¨åˆ†æ˜¯å¦‚ä½•å¤„ç†ä¸ç¨³å®šçš„ä¸Šæ¸¸é›†ã€‚å®¹å™¨æ¥æ¥å»å»ï¼Œå®ƒä»¬çš„ IP åœ°å€æ˜¯çŸ­æš‚çš„ã€‚å› æ­¤ï¼Œæ¯å½“åº”ç”¨ç¨‹åºå®¹å™¨åˆ—è¡¨å‘ç”Ÿå˜åŒ–æ—¶ï¼Œä»£ç†éƒ½éœ€è¦æ›´æ–°å…¶ä¸Šæ¸¸ IP åˆ—è¡¨ã€‚ Docker æœ‰ä¸€ä¸ªå†…ç½®çš„ DNS æœåŠ¡å™¨ï¼Œç”¨äºç»´æŠ¤å®¹å™¨çš„æœ€æ–° DNS è®°å½•ã€‚ä½†æ˜¯ï¼Œ[Nginx ä¸ä¼šåˆ·æ–° DNS è§£æç»“æœï¼Œé™¤éåº”ç”¨äº†ä¸€äº›å¸¦æœ‰å˜é‡çš„é­”æ³•](https://www.ameyalokare.com/docker/2017/09/27/nginx-dynamic-upstreams-docker.html)ã€‚é…ç½® [ä½¿ç”¨ STRICT\_DNS é›†ç¾¤çš„ Envoy ä»£ç†å¯èƒ½ä¼šæ˜¾ç¤ºæ›´å¥½çš„ç»“æœ](https://www.redhat.com/en/blog/configuring-envoy-auto-discover-pods-kubernetes)ã€‚ç„¶è€Œï¼Œåªæœ‰é€šè¿‡[åŠ¨æ€æ›´æ–°ä»£ç†é…ç½®ä»¥ç›‘å¬ Docker äº‹ä»¶](http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-ç å¤´å·¥äºº/)ã€‚

![Multiple Docker containers behind a reverse proxy.](http://iximiuz.com/multiple-containers-same-port-reverse-proxy/multiple-containers-same-port-proxy-2000-opt.png)

Luckily, there is a more modern proxy called [Traefik](https://traefik.io/traefik/) with built-in support for many service discovery mechanisms, including labeled Docker containers. If you want to see Traefik in action, check out my write-up on [canary container deployments](http://iximiuz.com/en/posts/traefik-canary-deployments-with-weighted-load-balancing/).

å¹¸è¿çš„æ˜¯ï¼Œæœ‰ä¸€ä¸ªæ›´ç°ä»£çš„ä»£ç†å«åš [Traefik](https://traefik.io/traefik/)ï¼Œå®ƒå†…ç½®äº†å¯¹è®¸å¤šæœåŠ¡å‘ç°æœºåˆ¶çš„æ”¯æŒï¼ŒåŒ…æ‹¬æ ‡è®°çš„ Docker å®¹å™¨ã€‚å¦‚æœæ‚¨æƒ³çœ‹åˆ° Traefik çš„å®é™…åº”ç”¨ï¼Œè¯·æŸ¥çœ‹æˆ‘å…³äº [canary å®¹å™¨éƒ¨ç½²](http://iximiuz.com/en/posts/traefik-canary-deployments-with-weighted-load-balancing/) çš„æ–‡ç« ã€‚

Well, that's it for now. Make code, not war!

å—¯ï¼Œæš‚æ—¶å°±è¿™äº›ã€‚ç¼–å†™ä»£ç ï¼Œè€Œä¸æ˜¯æˆ˜äº‰ï¼

#### Resources

####  èµ„æº

- [Historical overview of SO\_REUSEADDR and SO\_REUSEPORT options](https://stackoverflow.com/questions/14388706/how-do-so-reuseaddr-and-so-reuseport-differ/14388707#14388707)
- [The SO\_REUSEPORT socket option](https://lwn.net/Articles/542629/) \- LWN article by Michael Kerrisk
- [The docker-proxy](https://windsock.io/the-docker-proxy/) 

- [SO\_REUSEADDR å’Œ SO\_REUSEPORT é€‰é¡¹çš„å†å²æ¦‚è¿°](https://stackoverflow.com/questions/14388706/how-do-so-reuseaddr-and-so-reuseport-difer/14388707#14388707)
- [SO\_REUSEPORT å¥—æ¥å­—é€‰é¡¹](https://lwn.net/Articles/542629/) \- Michael Kerrisk çš„ LWN æ–‡ç« 
- [ç å¤´ä»£ç†](https://windsock.io/the-docker-proxy/)

- [Cracking Kubernetes node proxy (aka kube-proxy)](https://arthurchiao.art/blog/cracking-k8s-node-proxy/)
- [Dynamic Nginx configuration for Docker with Python](https://www.ameyalokare.com/docker/2017/09/27/nginx-dynamic-upstreams-docker.html)
- [Automated Nginx Reverse Proxy for Docker](http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/)
- [nginx-proxy/nginx-proxy](https://github.com/nginx-proxy/nginx-proxy) and [nginx-proxy/docker-gen](https://github.com/nginx-proxy/docker-gen) GitHub projects.
- [Configuring Envoy to Auto-Discover Pods on Kubernetes](https://www.redhat.com/en/blog/configuring-envoy-auto-discover-pods-kubernetes)

- [ç ´è§£ Kubernetes èŠ‚ç‚¹ä»£ç†ï¼ˆåˆå kube-proxyï¼‰](https://arthurchio.art/blog/cracking-k8s-node-proxy/)
- [Docker ä¸ Python çš„åŠ¨æ€ Nginx é…ç½®](https://www.ameyalokare.com/docker/2017/09/27/nginx-dynamic-upstreams-docker.html)
- [Docker çš„è‡ªåŠ¨åŒ– Nginx åå‘ä»£ç†](http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/)
- [nginx-proxy/nginx-proxy](https://github.com/nginx-proxy/nginx-proxy) å’Œ [nginx-proxy/docker-gen](https://github.com/nginx-proxy/docker-gen) GitHub é¡¹ç›®ã€‚
- [é…ç½® Envoy ä»¥åœ¨ Kubernetes ä¸Šè‡ªåŠ¨å‘ç° Pod](https://www.redhat.com/en/blog/configuring-envoy-auto-discover-pods-kubernetes)

#### Related posts

####  ç›¸å…³æ–‡ç« 

- [Container Networking Is Simple!](http://iximiuz.com/en/posts/container-networking-is-simple/)
- [Illustrated introduction to Linux iptables](http://iximiuz.com/en/posts/laymans-iptables-101/)
- [Traefik: canary deployments with weighted load balancing](http://iximiuz.com/en/posts/traefik-canary-deployments-with-weighted-load-balancing/)
- [Service Discovery in Kubernetes - Combining the Best of Two Worlds](http://iximiuz.com/en/posts/service-discovery-in-kubernetes/)
- [Writing Web Server in Python: sockets](http://iximiuz.com/en/posts/writing-web-server-in-python-sockets/)
- [Exploring Go net/http Package - On How Not To Set Socket Options](http://iximiuz.com/en/posts/go-net-http-setsockopt-example/)

- [å®¹å™¨ç½‘ç»œå¾ˆç®€å•ï¼](http://iximiuz.com/en/posts/container-networking-is-simple/)
-  [Linux iptables å›¾è§£ä»‹ç»](http://iximiuz.com/en/posts/laymans-iptables-101/)
- [Traefikï¼šå…·æœ‰åŠ æƒè´Ÿè½½å¹³è¡¡çš„é‡‘ä¸é›€éƒ¨ç½²](http://iximiuz.com/en/posts/traefik-canary-deployments-with-weighted-load-balancing/)
- [Kubernetes ä¸­çš„æœåŠ¡å‘ç° - ç»“åˆä¸¤å…¨å…¶ç¾](http://iximiuz.com/en/posts/service-discovery-in-kubernetes/)
- [ç”¨ Python ç¼–å†™ Web æœåŠ¡å™¨ï¼šsockets](http://iximiuz.com/en/posts/writing-web-server-in-python-sockets/)
- [æ¢ç´¢ Go net/http åŒ… - å…³äºå¦‚ä½•ä¸è®¾ç½®å¥—æ¥å­—é€‰é¡¹](http://iximiuz.com/en/posts/go-net-http-setsockopt-example/)

[golang,](javascript: void 0) [socket,](javascript: void 0) [docker,](javascript: void 0) [iptables](javascript: void 0)

[golang,](javascript: void 0) [socket,](javascript: void 0) [docker,](javascript: void 0) [iptables](javascript: void 0)

#### Written by Ivan Velichko

#### ç”±ä¼Šä¸‡Â·ç»´åˆ©å¥‡ç§‘ (Ivan Velichko) æ’°å†™

_Follow me on twitter [@iximiuz](https://twitter.com/iximiuz)_

_åœ¨æ¨ç‰¹ä¸Šå…³æ³¨æˆ‘ [@iximiuz](https://twitter.com/iximiuz)_

Liked this article? Let it be the beginning of a great friendship. Leave your email so I could notify you about new articles or any other interesting happenings around the topics of this blog. No spam whatsoever, I promise!

å–œæ¬¢è¿™ç¯‡æ–‡ç« å—ï¼Ÿè®©å®ƒæˆä¸ºä¸€æ®µä¼Ÿå¤§å‹è°Šçš„å¼€å§‹ã€‚ç•™ä¸‹æ‚¨çš„ç”µå­é‚®ä»¶ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥é€šçŸ¥æ‚¨æœ‰å…³æ­¤åšå®¢ä¸»é¢˜çš„æ–°æ–‡ç« æˆ–ä»»ä½•å…¶ä»–æœ‰è¶£çš„äº‹ä»¶ã€‚æ²¡æœ‰ä»»ä½•åƒåœ¾é‚®ä»¶ï¼Œæˆ‘ä¿è¯ï¼

Copyright Ivan Velichko Â© 2021Â FeedÂ [Atom](http://iximiuz.com/feed.atom)[RSS](http://iximiuz.com/feed.rss) 

ç‰ˆæƒæ‰€æœ‰ Ivan Velichko Â© 2021 Feed [Atom](http://iximiuz.com/feed.atom)[RSS](http://iximiuz.com/feed.rss)

